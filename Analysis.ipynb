{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# %matplotlib widget\n",
    "# %matplotlib qt5\n",
    "%matplotlib qt5",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import h5py\n",
    "import os\n",
    "import scipy.optimize as opt\n",
    "from lmfit import Model, create_params, minimize\n",
    "from lmfit.printfuncs import report_fit\n",
    "\n",
    "\n",
    "# create a color maps from DARK2\n",
    "\n",
    "def get_colors(n):\n",
    "    from matplotlib.cm import Dark2\n",
    "    return Dark2(np.linspace(0,1,n))\n",
    "\n",
    "# plt.style.use('prx')\n",
    "plt.style.use('S:\\Connie\\prx.mplstyle')\n",
    "# data_dir = '/Volumes/slab/QRAM/qram_4QR2/data/'\n",
    "data_dir = 'S:/QRAM/qram_4QR2/data/'\n",
    "\n",
    "# plt.style.use('paper_2')\n",
    "\n",
    "# fontsize = 13\n",
    "\n",
    "# %config InlineBackend.figure_format = 'svg'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sweep = np.linspace(0, 100, 100)\n",
    "plt.figure()\n",
    "for i in range(6):\n",
    "    plt.plot(x_sweep, i*np.ones_like(x_sweep))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %aimport experiments\n",
    "import experiments as meas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config_file = 'config_zcu216.yml'\n",
    "# config_file = 'config_q3diamond.yml'\n",
    "config_file = 'config_q3diamond_full688and638_reset.yml'\n",
    "config_path = os.path.join('s:\\\\Connie\\\\experiments\\\\qram_tprocv1_expts\\\\configs\\\\', config_file)\n",
    "print('Config will be', config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from slab.datamanagement import SlabFile\n",
    "import json\n",
    "from slab import get_next_filename, AttrDict\n",
    "\n",
    "\"\"\"Reopen saved data\"\"\"\n",
    "def prev_data(expt_path, filename=None):\n",
    "    temp_data_file = expt_path\n",
    "    if filename is not None: temp_data_file = os.path.join(expt_path, filename)\n",
    "    print(temp_data_file)\n",
    "    with SlabFile(temp_data_file) as a:\n",
    "        attrs = dict()\n",
    "        for key in list(a.attrs):\n",
    "            attrs.update({key:json.loads(a.attrs[key])})\n",
    "        keys = list(a)\n",
    "        temp_data = dict()\n",
    "        for key in keys:\n",
    "            temp_data.update({key:np.array(a[key])})\n",
    "        print(f'Extracted data and attrs {list(a.attrs)}')\n",
    "    return temp_data, attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the h5 file and check the keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '_rabi_EgGf_freqlen_chevron_qubit21.h5'\n",
    "folder = 'data_240617'\n",
    "idx_name = np.arange(25, 49, 1)\n",
    "\n",
    "amps = []\n",
    "freqs = []\n",
    "time = []\n",
    "I = []\n",
    "Q = []\n",
    "\n",
    "# open all file that contains the filename str in the folder\n",
    "for i in idx_name:\n",
    "        _filename = '000' + str(i) + filename \n",
    "        file = h5py.File(folder+'/'+_filename, 'r')\n",
    "        _amps = file['amps']\n",
    "        _freqs = file['freqpts']\n",
    "        _time = file['lenpts']\n",
    "        _i = file['avgi']\n",
    "        _q = file['avgq']\n",
    "        amps.append(np.array(_amps))\n",
    "        freqs.append(np.array(_freqs))\n",
    "        time.append(np.array(_time))\n",
    "        I.append(np.array(_i))\n",
    "        Q.append(np.array(_q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a 2d maps of the amps vs freqs and gain\n",
    "\n",
    "# plot all file \n",
    "\n",
    "qb = 0\n",
    "\n",
    "\n",
    "for i in idx_name:\n",
    "    idx = np.unravel_index(np.argmax(amps[i-25][qb], axis=None), amps[i-25][qb].shape)\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "    ax.imshow(amps[i-25][qb], aspect='auto', extent=[time[i-25][1], time[i-25][-1], freqs[i-25][0], freqs[i-25][-1]])\n",
    "\n",
    "    ax.plot(time[i-25][idx[1]], freqs[i-25][idx[0]], 'ro')\n",
    "    ax.set_title('file ' + str(i))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each file take the frequency slice for which the amplitude is maximum\n",
    "fig, ax = plt.subplots(1, 2, figsize=(7, 5))\n",
    "for i in idx_name[5:14]:\n",
    "\n",
    "    idx = np.unravel_index(np.argmax(amps[i-25][qb], axis=None), amps[i-25][qb].shape)\n",
    "    _amp_plot_time = amps[i-25][qb][idx[0], :]\n",
    "    ax[0].plot(time[i-25], _amp_plot_time, label='file ' + str(i))\n",
    "    ax[0].set_title('Amp vs time')\n",
    "    _amp_plot_freq = amps[i-25][qb][:, idx[1]] \n",
    "    ax[1].plot(freqs[i-25], _amp_plot_freq, label='file ' + str(i))\n",
    "    ax[1].set_title('Amp vs freq')\n",
    "\n",
    "\n",
    "\n",
    "# ax.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check the ramp time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '_rabi_EgGf_freqlen_chevron_qubit21.h5'\n",
    "# folder = 'data_240617'\n",
    "idx_name = np.array([122, 139,146, 148, 149, 151])\n",
    "\n",
    "amps = []\n",
    "freqs = []\n",
    "time = []\n",
    "I = []\n",
    "Q = []\n",
    "\n",
    "# open all file that contains the filename str in the folder\n",
    "for i in idx_name:\n",
    "        _filename = '00' + str(i) + filename \n",
    "        print(_filename)\n",
    "        # file = h5py.File(folder+'/'+_filename, 'r')\n",
    "        file = h5py.File(_filename, 'r')\n",
    "        _amps = file['amps']\n",
    "        _freqs = file['freqpts']\n",
    "        _time = file['lenpts']\n",
    "        _i = file['avgi']\n",
    "        _q = file['avgq']\n",
    "        amps.append(np.array(_amps))\n",
    "        freqs.append(np.array(_freqs))\n",
    "        time.append(np.array(_time))\n",
    "        I.append(np.array(_i))\n",
    "        Q.append(np.array(_q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a 2d maps of the amps vs freqs and gain\n",
    "\n",
    "# plot all file \n",
    "\n",
    "qb = 0\n",
    "\n",
    "\n",
    "for i in range(len(idx_name)):\n",
    "    idx = np.unravel_index(np.argmax(amps[i][qb], axis=None), amps[i][qb].shape)\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "    ax.imshow(amps[i][qb], aspect='auto', extent=[time[i][1], time[i][-1], freqs[i][0], freqs[i][-1]])\n",
    "\n",
    "    ax.plot(time[i][idx[1]], freqs[i][idx[0]], 'ro')\n",
    "    ax.set_title('file ' + str(i))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each file plot the slice \n",
    "\n",
    "# time_to_plot = [0.250, 0.580]\n",
    "# time_to_plot = [0.2, 0.3, 0.4, 0.5, 0.6, 0.9, 1, 1.1]\n",
    "time_to_plot = time[-1]\n",
    "\n",
    "for i in range(len(idx_name)):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "    print(amps[i].shape)\n",
    "    idx_plot = [np.argmin(np.abs(time[i] - time_to_plot[p])) for p in range(len(time_to_plot))]\n",
    "    [ax.plot(freqs[i], amps[i][qb][:, idx_plot[p]], label='time = ' + str(time[i][idx_plot[p]])) for p in range(len(time_to_plot))]\n",
    "    # for each trace and a point for the max \n",
    "    [ax.plot(freqs[i][np.argmax(amps[i][qb][:, idx_plot[p]])], np.max(amps[i][qb][:, idx_plot[p]]), 'ro') for p in range(len(time_to_plot))]\n",
    "    ax.legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qubit monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qubits = [0,1,2,3]\n",
    "file_name_qubit = ['00012', '00025', '00013', '00014']\n",
    "folder = 'data_240617'\n",
    "\n",
    "t1_tab = []\n",
    "t1err_tab = []\n",
    "time_t1_tab = []\n",
    "t2_tab = []\n",
    "t2err_tab = []\n",
    "time_t2_tab = []\n",
    "qb_freq = []\n",
    "for idxq, qubit_i in enumerate(qubits):\n",
    "        \n",
    "    fname_t1 = file_name_qubit[qubit_i] + f'_t1_time_sweep_qubit{qubit_i}.h5'\n",
    "    fname_t2 = file_name_qubit[qubit_i] + f'_t2r_time_sweep_qubit{qubit_i}.h5'\n",
    "\n",
    "    file_t1 = h5py.File(folder +'/' + fname_t1, 'r')\n",
    "    file_t2 = h5py.File(folder+'/'+fname_t2, 'r')\n",
    "    \n",
    "    time_t1 = np.asarray(file_t1['times'])\n",
    "    t1_fit = np.asarray(file_t1['t1_fit'])\n",
    "    t1_fit_err = np.asarray(file_t1['t1_fit_err'])\n",
    "\n",
    "    time_t2r = np.asarray(file_t2['times'])\n",
    "    t2r_fit = np.asarray(file_t2['t2r_fit'])\n",
    "    t2r_fit_err = np.asarray(file_t2['t2r_fit_err'])\n",
    "    freq_qb = np.asarray(file_t2['freq_qb'])\n",
    "\n",
    "\n",
    "    t1_err_bounds = [0.01, 20]\n",
    "    t2r_err_bounds = [0.01, 100]\n",
    "    \n",
    "    idx_remove_t1 = np.where((t1_fit_err < t1_err_bounds[0]) | (t1_fit_err > t1_err_bounds[1]))[0]\n",
    "    idx_remove_t2r = np.where((t2r_fit_err < t2r_err_bounds[0]) | (t2r_fit_err > t2r_err_bounds[1]))[0]\n",
    "    \n",
    "\n",
    "    time_t1 = np.delete(time_t1, idx_remove_t1)\n",
    "    t1_fit = np.delete(t1_fit, idx_remove_t1)\n",
    "    t1_fit_err = np.delete(t1_fit_err, idx_remove_t1)\n",
    "\n",
    "    time_t2r = np.delete(time_t2r, idx_remove_t2r)\n",
    "    t2r_fit = np.delete(t2r_fit, idx_remove_t2r)\n",
    "    t2r_fit_err = np.delete(t2r_fit_err, idx_remove_t2r)\n",
    "    freq_qb = np.delete(freq_qb, idx_remove_t2r)\n",
    "    \n",
    "        \n",
    "    t1_tab.append(t1_fit)\n",
    "    t1err_tab.append(t1_fit_err)\n",
    "    time_t1_tab.append(time_t1)\n",
    "    \n",
    "    t2_tab.append(t2r_fit)\n",
    "    t2err_tab.append(t2r_fit_err)\n",
    "    time_t2_tab.append(time_t2r)\n",
    "    \n",
    "    qb_freq.append(freq_qb)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# freq_qb = file['freq_qb']\n",
    "# times = file['times']\n",
    "# filename = '00014_t2r_time_sweep_qubit1.h5'\n",
    "# folder = 'data_240617'\n",
    "# file = h5py.File(folder+'/'+filename, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 1, figsize=(6, 6), sharex=True)\n",
    "\n",
    "\n",
    "for idxq, qubit_i in enumerate(qubits):\n",
    "\n",
    "    ax[0].errorbar(time_t1_tab[idxq]/60/60, t1_tab[idxq], yerr=t1err_tab[idxq], fmt='o-',  elinewidth=1, \n",
    "                   label=f'Qubit {qubit_i}', markersize=3, linewidth=1)\n",
    "    ax[0].set_ylabel('T1 (us)')\n",
    "    # ax[0].set_xlabel('Time (hrs)')\n",
    "\n",
    "    ax[1].errorbar(time_t2_tab[idxq]/60/60, t2_tab[idxq], yerr=t2err_tab[idxq], fmt='o-', elinewidth=1,\n",
    "                    label=f'Qubit {qubit_i}', markersize=3, linewidth=1)\n",
    "    ax[1].set_ylabel('T2R (us)')\n",
    "    # ax[1].set_xlabel('Time (hrs)')\n",
    "\n",
    "    ax[2].plot(time_t2_tab[idxq]/60/60, (qb_freq[idxq] - np.mean(qb_freq[idxq])), 'o-', label=f'Qubit {qubit_i}',  markersize=3, linewidth=1)\n",
    "    ax[2].set_ylabel('Frequency shift (MHz)')\n",
    "    ax[2].set_xlabel('Time (hrs)')\n",
    "\n",
    "ax[0].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single shot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multihist(data, check_qubit, qubits, check_states, play_pulses_list, g_states, e_states, theta=None, plot=True, verbose=True, fit=True, mat=None, test=False):\n",
    "    \"\"\"\n",
    "    span: histogram limit is the mean +/- span\n",
    "    theta given and returned in deg\n",
    "    assume data is passed in form data['iqshots'] = [(idata, qdata)]*len(check_states), idata=[... *num_shots]*4\n",
    "    check_states: an array of strs of the init_state specifying each configuration to plot a histogram for\n",
    "    play_pulses_list: list of play_pulses corresponding to check_states, see code for play_pulses\n",
    "    g_states are indices to the check_states to categorize as \"g\" (the rest are \"e\")\n",
    "    \"\"\"\n",
    "    numbins = 200\n",
    "    shot_tab = []\n",
    "    bin_tab = []\n",
    "    p_tab = []\n",
    "    if fit: \n",
    "        amp_max = []\n",
    "        amp_min = []\n",
    "        amp_max_err = []\n",
    "        amp_min_err = []\n",
    "    \n",
    "    iqshots = data['iqshots']\n",
    "    if plot:\n",
    "        fig, axs = plt.subplots(nrows=2, ncols=2, figsize=(6, 6))\n",
    "        fig.suptitle(f'Readout on $|Q{qubits[0]}\\\\rangle |Q{qubits[1]}\\\\rangle$, check Q{check_qubit}')\n",
    "        fig.tight_layout()\n",
    "        # axs[0,0].set_xlabel('I [ADC levels]')\n",
    "        axs[0,0].set_ylabel('Q [ADC levels]')\n",
    "        axs[0,0].set_title('Unrotated')\n",
    "        axs[0,0].axis('equal')\n",
    "\n",
    "        # axs[0,1].set_xlabel('I [ADC levels]')\n",
    "        axs[0,1].axis('equal')\n",
    "\n",
    "        axs[1,0].set_ylabel('Counts')\n",
    "        axs[1,0].set_xlabel('I [ADC levels]')       \n",
    "\n",
    "        axs[1,1].set_xlabel('I [ADC levels]')\n",
    "\n",
    "        plt.subplots_adjust(hspace=0.25, wspace=0.15)        \n",
    "\n",
    "        Ig_tot = []\n",
    "        Qg_tot = []\n",
    "        Ie_tot = []\n",
    "        Qe_tot = []\n",
    "        for check_i, data_check in enumerate(iqshots):\n",
    "            I, Q = data_check\n",
    "            I = I[check_qubit]\n",
    "            Q = Q[check_qubit]\n",
    "            if check_i in g_states:\n",
    "                Ig_tot = np.concatenate((Ig_tot, I))\n",
    "                Qg_tot = np.concatenate((Qg_tot, Q))\n",
    "            elif check_i in e_states:\n",
    "                Ie_tot = np.concatenate((Ig_tot, I))\n",
    "                Qe_tot = np.concatenate((Qg_tot, Q))\n",
    "\n",
    "        \"\"\"Compute the rotation angle\"\"\"\n",
    "        if theta is None:\n",
    "            xg, yg = np.median(Ig_tot), np.median(Qg_tot)\n",
    "            xe, ye = np.median(Ie_tot), np.median(Qe_tot)\n",
    "            theta = -np.arctan2((ye-yg), (xe-xg))\n",
    "        else: theta *= np.pi/180\n",
    "\n",
    "        Ig_tot_new = Ig_tot*np.cos(theta) - Qg_tot*np.sin(theta)\n",
    "        Qg_tot_new = Ig_tot*np.sin(theta) + Qg_tot*np.cos(theta) \n",
    "        Ie_tot_new = Ie_tot*np.cos(theta) - Qe_tot*np.sin(theta)\n",
    "        Qe_tot_new = Ie_tot*np.sin(theta) + Qe_tot*np.cos(theta) \n",
    "        I_tot_new = np.concatenate((Ie_tot_new, Ig_tot_new))\n",
    "        span = (np.max(I_tot_new) - np.min(I_tot_new))/2\n",
    "        midpoint = (np.max(I_tot_new) + np.min(I_tot_new))/2\n",
    "        xlims = [midpoint-span, midpoint+span]\n",
    "\n",
    "    n_tot_g = [0]*numbins\n",
    "    n_tot_e = [0]*numbins\n",
    "    for check_i, data_check in enumerate(iqshots):\n",
    "        check_state = check_states[check_i]\n",
    "        play_pulses = play_pulses_list[check_i]\n",
    "\n",
    "        I, Q = data_check\n",
    "        I = I[check_qubit]\n",
    "        Q = Q[check_qubit]\n",
    "\n",
    "        xmed, ymed = np.median(I), np.median(Q)\n",
    "\n",
    "        if verbose:\n",
    "            print(check_state, 'play_pulses', play_pulses, 'unrotated medians:')\n",
    "            print(f'I {xmed} +/- {np.std(I)} \\t Q {ymed} +/- {np.std(Q)} \\t Amp {np.abs(xmed+1j*ymed)}')\n",
    "\n",
    "        \"\"\"Rotate the IQ data\"\"\"\n",
    "        I_new = I*np.cos(theta) - Q*np.sin(theta)\n",
    "        Q_new = I*np.sin(theta) + Q*np.cos(theta) \n",
    "\n",
    "        \"\"\"New means of each blob\"\"\"\n",
    "        xmed_new, ymed_new = np.median(I_new), np.median(Q_new)\n",
    "        if verbose:\n",
    "            print(f'Rotated (theta={theta}):')\n",
    "            print(f'I {xmed_new} +/- {np.std(I_new)} \\t Q {ymed_new} +/- {np.std(Q_new)} \\t Amp {np.abs(xmed_new+1j*ymed_new)}')\n",
    "\n",
    "        if plot:\n",
    "            label = f'{check_state}'\n",
    "            if len(play_pulses) > 1 or play_pulses[0] != 0:\n",
    "                label += f' play {play_pulses}'\n",
    "            axs[0,0].scatter(I, Q, label=label, marker='.', edgecolor='None', alpha=0.3)\n",
    "            axs[0,0].plot([xmed], [ymed], color='k', linestyle=':', marker='o', markersize=5)\n",
    "\n",
    "            axs[0,1].scatter(I_new, Q_new, label=label, marker='.', edgecolor='None', alpha=0.3)\n",
    "            axs[0,1].plot([xmed_new], [ymed_new], color='k', linestyle=':', marker='o', markersize=5)\n",
    "\n",
    "\n",
    "            n, bins, p = axs[1,0].hist(I_new, bins=numbins, range=xlims,  label=label, histtype='step')\n",
    "\n",
    "            if fit:\n",
    "                # fit with a double gaussian\n",
    "                p_guess = [np.max(n), xmed_new, 100, np.max(n), xmed_new - 200, 100]\n",
    "                bounds = ([0, xmed_new-200, 0, 0, xmed_new-1000, 0], [np.inf, xmed_new+1000, np.inf, np.inf, xmed_new, np.inf])\n",
    "                popt, pcov = opt.curve_fit(double_gaussian, bins[:-1], n, p0=p_guess, maxfev=10000, xtol=1e-15, ftol=1e-15, bounds=bounds)\n",
    "                perr = np.sqrt(np.diag(pcov))\n",
    "                axs[1,0].plot(bins[:-1], double_gaussian(bins[:-1], *popt), color='black')\n",
    "\n",
    "                id_max = np.argmax([popt[0], popt[3]])\n",
    "\n",
    "                if id_max == 0:\n",
    "                    amp_max.append(popt[0])\n",
    "                    amp_min.append(popt[3])\n",
    "                    amp_max_err.append(perr[0])\n",
    "                    amp_min_err.append(perr[3])\n",
    "                else:\n",
    "                    amp_max.append(popt[3])\n",
    "                    amp_min.append(popt[0])\n",
    "                    amp_max_err.append(perr[3])\n",
    "                    amp_min_err.append(perr[0])\n",
    "\n",
    "                print('state: ' + check_state)\n",
    "                print('amp_max: ', amp_max[-1], '+/-', amp_max_err[-1])\n",
    "                print('amp_min: ', amp_min[-1], '+/-', amp_min_err[-1])\n",
    "                print('pop wrong state (%): ', amp_min[-1]/(amp_max[-1] + amp_min[-1])*100)\n",
    "\n",
    "                p_min = amp_min[-1]/(amp_max[-1] + amp_min[-1])\n",
    "                p_max = amp_max[-1]/(amp_max[-1] + amp_min[-1])\n",
    "                p_vec = np.array([p_min, p_max])\n",
    "                p_tab.append(p_vec)\n",
    "\n",
    "\n",
    "        \n",
    "            axs[1,1].plot(bins[:-1], np.cumsum(n)/n.sum(), label=label)\n",
    "\n",
    "        else: # just getting the n, bins for data processing\n",
    "            n, bins = np.histogram(I_new, bins=numbins, range=xlims)\n",
    "\n",
    "        shot_tab.append(n)\n",
    "        bin_tab.append(bins)\n",
    "\n",
    "        if check_i in g_states: \n",
    "            n_tot_g += n\n",
    "            bins_g = bins\n",
    "        elif check_i in e_states: \n",
    "            n_tot_e += n\n",
    "            bins_e = bins\n",
    "\n",
    "\n",
    "    \"\"\"Compute the fidelity using overlap of the histograms\"\"\"\n",
    "    fids = []\n",
    "    thresholds = []\n",
    "    contrast = np.abs(np.cumsum(n_tot_g)/n_tot_g.sum() - np.cumsum(n_tot_e)/n_tot_e.sum())\n",
    "    tind=contrast.argmax()\n",
    "    thresholds.append(bins[tind])\n",
    "    fids.append(contrast[tind])\n",
    "\n",
    "    # calibration matrix\n",
    "\n",
    "    mat = np.zeros((2, 2))\n",
    "    idx_g = np.argmin(np.abs(bins_g- thresholds[-1]))\n",
    "\n",
    "    print('idx_g', idx_g)\n",
    "    print(bins_g[idx_g])\n",
    "    print(thresholds[-1])\n",
    "\n",
    "    mat[0, 0] = np.sum(n_tot_g[:idx_g])\n",
    "    mat[1, 0] = np.sum(n_tot_g[idx_g:])\n",
    "\n",
    "    idx_e = np.argmin(np.abs(bins_e - thresholds[-1]))\n",
    "    print('idx_e', idx_e)\n",
    "    print(bins_e[idx_e])\n",
    "    print(thresholds[-1])\n",
    "    mat[0, 1] = np.sum(n_tot_e[:idx_e])\n",
    "    mat[1, 1] = np.sum(n_tot_e[idx_e:])\n",
    "\n",
    "    mat /= np.sum(n_tot_e)\n",
    "    print('calibration matrix')\n",
    "    print(mat)\n",
    "\n",
    "    # apply calibration matrix to all state \n",
    "\n",
    "    mat_inv = np.linalg.inv(mat)\n",
    "    n_tab = []\n",
    "\n",
    "    for idx in range(len(shot_tab)):\n",
    "        thresh = np.argmin(np.abs(bin_tab[idx]- thresholds[-1]))\n",
    "        n_g = np.sum(shot_tab[idx][:thresh])\n",
    "        n_e = np.sum(shot_tab[idx][thresh:])\n",
    "        n = np.array([n_g, n_e])\n",
    "        n = n/np.sum(n)\n",
    "        n = np.dot(mat_inv, n)\n",
    "        n_tab.append(n)\n",
    "        print('state: ', check_states[idx])\n",
    "        print('calibrated state: ', n)\n",
    "\n",
    "\n",
    "\n",
    "    if plot: \n",
    "        axs[0,1].set_title(f'Rotated ($\\\\theta={theta*180/np.pi:.5}^\\\\circ$)')\n",
    "        \n",
    "        axs[1,0].axvline(thresholds[0], color='0.2', linestyle='--')\n",
    "        axs[1,0].set_title(f'Fidelity g-e: {100*fids[0]:.3}%')\n",
    "\n",
    "        axs[1,1].plot(bins[:-1], np.cumsum(n_tot_g)/n_tot_g.sum(), 'b', label='g')\n",
    "        axs[1,1].plot(bins[:-1], np.cumsum(n_tot_e)/n_tot_e.sum(), 'r', label='e')\n",
    "        axs[1,1].axvline(thresholds[0], color='0.2', linestyle='--')\n",
    "\n",
    "        prop = {'size': 8}\n",
    "        axs[0,0].legend(loc='upper right', prop=prop)\n",
    "        axs[0,1].legend(loc='upper right', prop=prop)\n",
    "        axs[1,0].legend(loc='upper left', prop=prop)\n",
    "        axs[1,1].legend(prop=prop)\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "    if test: \n",
    "\n",
    "        # plot \n",
    "        fig2, ax2 = plt.subplots(1, 1, figsize=(6, 6))\n",
    "\n",
    "        # fit the histogram with a double gaussian\n",
    "\n",
    "        xmax_g = bins_g[np.argmax(n_tot_g)]\n",
    "        xmax_e = bins_e[np.argmax(n_tot_e)]\n",
    "\n",
    "        ymax_g = np.max(n_tot_g)\n",
    "        ymax_e = np.max(n_tot_e)\n",
    "\n",
    "        print('xmax_g', xmax_g)\n",
    "        print('xmax_e', xmax_e)\n",
    "        print('ymax_g', ymax_g)\n",
    "        print('ymax_e', ymax_e)\n",
    "\n",
    "        popt_g = [ymax_g, xmax_g, 100, ymax_e, xmax_e, 100]\n",
    "        popt_e = [ymax_e, xmax_e, 100, ymax_g, xmax_g, 100]\n",
    "\n",
    "\n",
    "\n",
    "        # bounds = ([0, 0, bins_g[0], 0, 0, bins_e[0], 0], [np.inf, np.inf, bins_g[-1], np.inf, np.inf, bins_e[-1], np.inf])\n",
    "\n",
    "\n",
    "        popt_g, pcov_g = opt.curve_fit(double_gaussian, bins_g[:-1], n_tot_g, p0=popt_g, maxfev=10000, xtol=1e-15, ftol=1e-15)\n",
    "        popt_e, pcov_e = opt.curve_fit(double_gaussian, bins_e[:-1], n_tot_e, p0=popt_e, maxfev=10000, xtol=1e-15, ftol=1e-15)\n",
    "\n",
    "        ax2.plot(bins[:-1], n_tot_g, label='g')\n",
    "        ax2.plot(bins[:-1], n_tot_e, label='e')\n",
    "\n",
    "        ax2.plot(bins_g[:-1], double_gaussian(bins_g[:-1], *popt_g), color='black')\n",
    "        ax2.plot(bins_e[:-1], double_gaussian(bins_e[:-1], *popt_e), color='black')\n",
    "\n",
    "        print('pop for g wrong state (%): ', popt_g[3]/(popt_g[0] + popt_g[3])*100)\n",
    "        print('pop for e wrong state (%): ', popt_e[3]/(popt_e[0] + popt_e[3])*100)\n",
    "\n",
    "    \n",
    "\n",
    "    return fids, thresholds, theta*180/np.pi, n_tab, p_tab # fids: ge, gf, ef\n",
    "\n",
    "\n",
    "# define a double gaussian function\n",
    "def double_gaussian(x, a1, b1, c1, a2, b2, c2):\n",
    "    return a1*np.exp(-(x - b1)**2/(2*c1**2)) + a2*np.exp(-(x - b2)**2/(2*c2**2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename1 = '00009_QramSingleShotHist.h5'\n",
    "# filename2 = '00010_QramSingleShotHist.h5'\n",
    "\n",
    "filename1 = '00005_QramSingleShotHist.h5'\n",
    "filename2 = '00006_QramSingleShotHist.h5'\n",
    "folder = 'data_240617'\n",
    "\n",
    "data1 = h5py.File(folder+'/'+filename1, 'r')\n",
    "data2 = h5py.File(folder+'/'+filename2, 'r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check_states = ['Q2Q1_|0>|0>', 'Q2Q1_|0>|1>', 'Q2Q1_|1>|0>', '|0>|1>']\n",
    "check_states = ['Q2Q1_|0>|0>', 'Q2Q1_|0>|1>', 'Q2Q1_|2>|0>', '|0>|1>']\n",
    "play_pulses_list = [[0], [0], [0], [1, 3], [1, 3], [1, 3], [1, 3]]\n",
    "\n",
    "# mat_cal = np.array([[0.930325, 0.11815 ], [0.069675, 0.88185 ]])\n",
    "# mat_cal = np.array([[0.95035, 0.057075], [0.04965,  0.942925]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fids, thresholds, angle, n_tab, p_tab = multihist(data=data1, check_qubit=2,\n",
    "                                    check_states=check_states,play_pulses_list=play_pulses_list,\n",
    "                                      qubits=[1,2], g_states=[0],e_states=[2], theta=None, plot=True, verbose=True, fit=True, test = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fids, thresholds, angle, n_tab, p_tab = multihist(data=data2, check_qubit=2,\n",
    "                                    check_states=check_states,play_pulses_list=play_pulses_list,\n",
    "                                      qubits=[1,2], g_states=[0],e_states=[2], theta=None, plot=True, verbose=True, fit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calib_amp1 = 100 - 5.612460159835197\n",
    "swap_amp1 = 100 - 14.457410445531224\n",
    "\n",
    "calib_amp2 = 100 - 9.421839753118547\n",
    "swap_amp2 = 100 - 16.02897011158023\n",
    "print('using gaussian fit')\n",
    "print('swap fidelity active cooldown: ', swap_amp1/calib_amp1*100)\n",
    "print('swap fidelity no cooldown: ', swap_amp2/calib_amp2*100)\n",
    "print('using threshold and calibration matrix')\n",
    "print('swap fidelity active cooldown: ', 0.94711731*100)\n",
    "print('swap fidelity no cooldown: ', 0.91866623*100)\n",
    "\n",
    "\n",
    "\n",
    "calib_amp1 = 100 - 5.612460159835197\n",
    "swap_amp1 = 100 - 10.314368687567882\n",
    "\n",
    "calib_amp2 = 100 - 3.4672368995299045\n",
    "swap_amp2 = 100 - 12.231930578660803\n",
    "\n",
    "print('only eg-gf')\n",
    "print('using gaussian fit')\n",
    "print('swap fidelity active cooldown: ', swap_amp1/calib_amp1*100)\n",
    "print('swap fidelity no cooldown: ', swap_amp2/calib_amp2*100)\n",
    "print('using threshold and calibration matrix')\n",
    "print('swap fidelity active cooldown: ', 0.94350158*100)\n",
    "print('swap fidelity no cooldown: ', 0.90828692*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fidelity versus number of swap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenumbers = ['00012', '00013','00014','00015','00016']\n",
    "\n",
    "\n",
    "fid_swap_thresh = []\n",
    "p_all = []\n",
    "\n",
    "\n",
    "for filenumber in filenumbers:\n",
    "    filename = filenumber + '_QramSingleShotHist.h5'\n",
    "    data = h5py.File(folder+'/'+filename, 'r')\n",
    "    fids, thresholds, angle, n_tab, p_tab  = multihist(data=data, check_qubit=2,\n",
    "                                    check_states=check_states,play_pulses_list=play_pulses_list,\n",
    "                                      qubits=[1,2], g_states=[0],e_states=[2], theta=None, plot=True, verbose=True, fit=True)\n",
    "    \n",
    "    print('fidelity: ', n_tab)\n",
    "    fid_swap_thresh.append(n_tab[-1][1])\n",
    "    p_all.append(p_tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "fid_swap_gauss = np.zeros(len(filenumbers))\n",
    "\n",
    "for l in range(len(p_all)):\n",
    "\n",
    "    p_calib = p_all[l][2][1]\n",
    "    p_swap = p_all[l][-1][1]\n",
    "    fid_swap_gauss[l] = p_swap/p_calib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 1+ 2*np.arange(len(filenumbers))\n",
    "y = np.array(fid_swap_thresh)\n",
    "y2 = fid_swap_gauss\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 4))\n",
    "\n",
    "ax.plot(x, y*100, 'o-', label='Threshold', color='#445fab')\n",
    "ax.plot(x, y2*100, marker='v', color='#ab4d44', markersize=8, label='Gaussian fit', linewidth=0)\n",
    "ax.set_xticks(x)\n",
    "\n",
    "ax.set_ylabel('EG-GF Fidelity (%)')\n",
    "ax.set_xlabel('Number of SWAP')\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the swap fidelity with the post selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '00152_length_rabi_EgGf_qubit21.h5'\n",
    "\n",
    "file = h5py.File(folder+'/'+filename, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.asanyarray(file['epop'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RB analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_name_str = ['gg', 'ge', 'eg', 'ee', 'gf', 'ef']\n",
    "\n",
    "state_subspace = ['eg', 'gf']\n",
    "\n",
    "state_leak = ['gg', 'ge', 'ee', 'ef']\n",
    "state_erasure = []\n",
    "\n",
    "# state_leak = ['gg']\n",
    "# # state_erasure = ['ee', 'ge', 'ef']\n",
    "# state_erasure = ['ee', 'ge']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_name_q1q2 = '00001_SimultaneousRBEgGf.h5'\n",
    "# file_name_q1q3 = '00003_SimultaneousRBEgGf.h5'\n",
    "\n",
    "# file_name_q1q2_irb = '00003_SimultaneousRBEgGf.h5'\n",
    "# file_name_q1q3_irb = '00001_SimultaneousRBEgGf.h5'\n",
    "\n",
    "\n",
    "file_name_q1q2 = '00015_rb_EgGf_qubit21.h5'\n",
    "file_name_q1q2_irb = '00016_rb_EgGf_qubit21.h5'\n",
    "\n",
    "file_name_q1q3 = '00007_rb_EgGf_qubit31.h5'\n",
    "file_name_q1q3_irb = '00008_rb_EgGf_qubit31.h5'\n",
    "\n",
    "\n",
    "folder = 'data_241025'\n",
    "file_path_q1q2 = data_dir +'/' + folder+'/'+file_name_q1q2\n",
    "file_path_q1q3 = data_dir +'/' + folder+'/'+file_name_q1q3\n",
    "file_path_q1q2_irb = data_dir +'/' + folder+'/'+file_name_q1q2_irb\n",
    "file_path_q1q3_irb = data_dir +'/' + folder+'/'+file_name_q1q3_irb\n",
    "# file_q1q2 = h5py.File(data_dir +'/' + folder+'/'+file_name_q1q2, 'r')\n",
    "# file_q1q3 = h5py.File(data_dir +'/' + folder+'/'+file_name_q1q3, 'r')\n",
    "# print(file_q1q3.keys())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(x, p, B, A):\n",
    "    return B*p**x + A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the q1q3 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbprog = meas.SimultaneousRBEgGfExperiment(config_file=config_path)\n",
    "temp_data, attrs = prev_data(file_path_q1q3)\n",
    "rbprog.data = temp_data\n",
    "rbprog.cfg = AttrDict(attrs['config'])\n",
    "rbprog.calib_order = attrs['calib_order']\n",
    "\n",
    "data_13 = rbprog.analyze(fit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xpts = file_q1q3['xpts']\n",
    "xpts = data_13['xpts']\n",
    "n= len(np.asarray(xpts)[0])\n",
    "z = 1.96\n",
    "\n",
    "# pop_13 = np.asarray(file_q1q3['poplns_2q'])\n",
    "pop_13 = np.asarray(data_13['poplns_2q'])\n",
    "\n",
    "pop_dict_13 = {}\n",
    "pop_dict_13['avg'] = {}\n",
    "pop_dict_13['err'] = {}\n",
    "for idx, state in enumerate(state_name_str):\n",
    "    pop_dict_13['avg'][state] = pop_13[:, :, idx].mean(axis=1)\n",
    "    pop_dict_13['err'][state] = pop_13[:, :, idx].std(axis=1)/np.sqrt(n)\n",
    "    \n",
    "\n",
    "# define the subspace population and its error\n",
    "popln_subspace_avg_13=  np.sum([pop_dict_13['avg'][state] for state in state_subspace], axis=0)\n",
    "_pop_temp = np.zeros_like(pop_13[:, :, 0])\n",
    "for idx, state in enumerate(state_name_str):\n",
    "    if state in state_subspace:\n",
    "        _pop_temp += pop_13[:, :, idx]\n",
    "popln_subspace_err_13 = np.std(_pop_temp, axis=1)/np.sqrt(n)\n",
    "\n",
    "\n",
    "# define the eg/(eg+gf) and its error\n",
    "popln_eg_13 = pop_dict_13['avg']['eg']\n",
    "popln_eg_renorm_13 = popln_eg_13/popln_subspace_avg_13\n",
    "\n",
    "idx_eg = state_name_str.index('eg')\n",
    "_pop_temp = pop_13[:, :, idx_eg]\n",
    "popln_eg_err_13 = np.std(_pop_temp, axis=1)/np.sqrt(n)\n",
    "\n",
    "idx_eg = state_name_str.index('eg')\n",
    "idx_gf = state_name_str.index('gf')\n",
    "_pop_temp = pop_13[:, :, idx_eg]/(pop_13[:, :, idx_eg] + pop_13[:, :, idx_gf])\n",
    "popln_eg_renorm_err_13 = np.std(_pop_temp, axis=1)/np.sqrt(n)\n",
    "\n",
    "popln_not_erase_13 = 1 - np.sum([pop_dict_13['avg'][state] for state in state_erasure], axis=0)\n",
    "_pop_temp = np.zeros_like(pop_13[:, :, 0])\n",
    "for idx, state in enumerate(state_name_str):\n",
    "    if state in state_erasure:\n",
    "        _pop_temp += pop_13[:, :, idx]\n",
    "popln_not_erase_err_13 = np.std(_pop_temp, axis=1)/np.sqrt(n)\n",
    "\n",
    "x_rb_13 = np.unique(xpts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the q1q2 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbprog = meas.SimultaneousRBEgGfExperiment(config_file=config_path)\n",
    "temp_data, attrs = prev_data(file_path_q1q3_irb)\n",
    "rbprog.data = temp_data\n",
    "rbprog.cfg = AttrDict(attrs['config'])\n",
    "rbprog.calib_order = attrs['calib_order']\n",
    "\n",
    "data_13_x = rbprog.analyze(fit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xpts_x = file_x_q1q3['xpts']\n",
    "xpts_x = data_13_x['xpts']\n",
    "n_x = len(np.asarray(xpts_x)[0])\n",
    "\n",
    "# pop_13 = np.asarray(file_x_q1q3['poplns_2q'])\n",
    "pop_13 = np.asarray(data_13_x['poplns_2q'])\n",
    "\n",
    "pop_dict_x_13 = {}\n",
    "pop_dict_x_13['avg'] = {}\n",
    "pop_dict_x_13['err'] = {}\n",
    "\n",
    "\n",
    "for idx, state in enumerate(state_name_str):\n",
    "    pop_dict_x_13['avg'][state] = pop_13[:, :, idx].mean(axis=1)\n",
    "    pop_dict_x_13['err'][state] = pop_13[:, :, idx].std(axis=1)/np.sqrt(n_x)\n",
    "\n",
    "popln_subspace_avg_x_13=  np.sum([pop_dict_x_13['avg'][state] for state in state_subspace], axis=0)\n",
    "_pop_temp = np.zeros_like(pop_13[:, :, 0])\n",
    "for idx, state in enumerate(state_name_str):\n",
    "    if state in state_subspace:\n",
    "        _pop_temp += pop_13[:, :, idx]\n",
    "popln_subspace_err_x_13 = np.std(_pop_temp, axis=1)/np.sqrt(n_x)\n",
    "\n",
    "popln_eg_x_13 = pop_dict_x_13['avg']['eg']\n",
    "popln_eg_renorm_x_13 = popln_eg_x_13/popln_subspace_avg_x_13\n",
    "\n",
    "idx_eg = state_name_str.index('eg')\n",
    "_pop_temp = pop_13[:, :, idx_eg]\n",
    "popln_eg_err_x_13 = np.std(_pop_temp, axis=1)/np.sqrt(n_x)\n",
    "\n",
    "idx_eg = state_name_str.index('eg')\n",
    "idx_gf = state_name_str.index('gf')\n",
    "_pop_temp = pop_13[:, :, idx_eg]/(pop_13[:, :, idx_eg] + pop_13[:, :, idx_gf])\n",
    "popln_eg_renorm_err_x_13 = np.std(_pop_temp, axis=1)/np.sqrt(n_x)\n",
    "\n",
    "popln_not_erase_x_13 = 1 - np.sum([pop_dict_x_13['avg'][state] for state in state_erasure], axis=0)\n",
    "_pop_temp = np.zeros_like(pop_13[:, :, 0])\n",
    "for idx, state in enumerate(state_name_str):\n",
    "    if state in state_erasure:\n",
    "        _pop_temp += pop_13[:, :, idx]\n",
    "popln_not_erase_err_x_13 = np.std(_pop_temp, axis=1)/np.sqrt(n_x)\n",
    "\n",
    "x_rb_x_13 = np.unique(xpts_x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the q1q2 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbprog = meas.SimultaneousRBEgGfExperiment(config_file=config_path)\n",
    "temp_data, attrs = prev_data(file_path_q1q3_irb)\n",
    "rbprog.data = temp_data\n",
    "rbprog.cfg = AttrDict(attrs['config'])\n",
    "rbprog.calib_order = attrs['calib_order']\n",
    "\n",
    "data = rbprog.analyze(fit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xpts_x = file_x_q1q3['xpts']\n",
    "xpts_x = data['xpts']\n",
    "n_x = len(np.asarray(xpts_x)[0])\n",
    "\n",
    "# pop_13 = np.asarray(file_x_q1q3['poplns_2q'])\n",
    "pop_13 = np.asarray(data['poplns_2q'])\n",
    "\n",
    "pop_dict_x_13 = {}\n",
    "pop_dict_x_13['avg'] = {}\n",
    "pop_dict_x_13['err'] = {}\n",
    "\n",
    "\n",
    "for idx, state in enumerate(state_name_str):\n",
    "    pop_dict_x_13['avg'][state] = pop_13[:, :, idx].mean(axis=1)\n",
    "    pop_dict_x_13['err'][state] = pop_13[:, :, idx].std(axis=1)/np.sqrt(n_x)\n",
    "\n",
    "popln_subspace_avg_x_13=  np.sum([pop_dict_x_13['avg'][state] for state in state_subspace], axis=0)\n",
    "_pop_temp = np.zeros_like(pop_13[:, :, 0])\n",
    "for idx, state in enumerate(state_name_str):\n",
    "    if state in state_subspace:\n",
    "        _pop_temp += pop_13[:, :, idx]\n",
    "popln_subspace_err_x_13 = np.std(_pop_temp, axis=1)/np.sqrt(n_x)\n",
    "\n",
    "popln_eg_renorm_x_13 = pop_dict_x_13['avg']['eg']/popln_subspace_avg_x_13\n",
    "idx_eg = state_name_str.index('eg')\n",
    "idx_gf = state_name_str.index('gf')\n",
    "_pop_temp = pop_13[:, :, idx_eg]/(pop_13[:, :, idx_eg] + pop_13[:, :, idx_gf])\n",
    "popln_eg_renorm_err_x_13 = np.std(_pop_temp, axis=1)/np.sqrt(n_x)\n",
    "\n",
    "popln_not_erase_x_13 = 1 - np.sum([pop_dict_x_13['avg'][state] for state in state_erasure], axis=0)\n",
    "_pop_temp = np.zeros_like(pop_13[:, :, 0])\n",
    "for idx, state in enumerate(state_name_str):\n",
    "    if state in state_erasure:\n",
    "        _pop_temp += pop_13[:, :, idx]\n",
    "popln_not_erase_err_x_13 = np.std(_pop_temp, axis=1)/np.sqrt(n_x)\n",
    "\n",
    "x_rb_x_13 = np.unique(xpts_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = ([0, 0, 0], [1, np.inf, np.inf])\n",
    "\n",
    "popt_x_13, pcov = opt.curve_fit(fit, x_rb_x_13, popln_subspace_avg_x_13, sigma=popln_subspace_err_x_13, absolute_sigma=True,\n",
    "                            p0=[0.99, 0.01, 0.01], maxfev=10000, xtol=1e-15, ftol=1e-15, bounds=bounds)\n",
    "perr_x_13 = np.sqrt(np.diag(pcov))\n",
    "\n",
    "popt2_x_13, pcov2 = opt.curve_fit(fit, x_rb_x_13, popln_eg_renorm_x_13, p0=[0.8, 0.01, 0.01], sigma=popln_eg_renorm_err_x_13, absolute_sigma=True,\n",
    "                                maxfev=10000, xtol=1e-15, ftol=1e-15, bounds=bounds)\n",
    "perr2_x_13 = np.sqrt(np.diag(pcov2))\n",
    "\n",
    "popt3_x_13, pcov3 = opt.curve_fit(fit, x_rb_x_13, popln_not_erase_x_13, p0=[0.8, 0.01, 0.01], sigma=popln_not_erase_err_x_13, absolute_sigma=True,\n",
    "                                maxfev=10000, xtol=1e-15, ftol=1e-15, bounds=bounds)\n",
    "perr3_x_13 = np.sqrt(np.diag(pcov3))\n",
    "                     \n",
    "\n",
    "x_rb_fit_x_13 = np.linspace(0, np.max(x_rb_x_13), 1000)\n",
    "y_fit_pop_x_13 = fit(x_rb_fit_x_13, *popt_x_13)\n",
    "y_fit_leak_x_13 = fit(x_rb_fit_x_13, *popt2_x_13)\n",
    "y_fit_erase_x_13 = fit(x_rb_fit_x_13, *popt3_x_13)\n",
    "\n",
    "p1_x_13 = popt_x_13[0]\n",
    "p2_x_13 = popt2_x_13[0]\n",
    "p3_x_13 = popt3_x_13[0]\n",
    "L_x_13 = (1 - popt_x_13[2])*(1 - popt_x_13[0])\n",
    "Lerr_x_13 = L_x_13*np.sqrt((perr_x_13[2]/(1 - popt_x_13[2]))**2 + (perr_x_13[0]/(1 - popt_x_13[0]))**2)\n",
    "\n",
    "erase_x_13 = (1 - popt3_x_13[2])*(1 - popt3_x_13[0])\n",
    "erase_err_x_13 = erase_x_13*np.sqrt((perr3_x_13[2]/(1 - popt3_x_13[2]))**2 + (perr3_x_13[0]/(1 - popt3_x_13[0]))**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_dict_x_13['avg']['gg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popt_x_13, popt2_x_13, popt3_x_13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popt_13, popt2_13, popt3_13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the q1q2 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbprog = meas.SimultaneousRBEgGfExperiment(config_file=config_path)\n",
    "temp_data, attrs = prev_data(file_path_q1q2_irb)\n",
    "rbprog.data = temp_data\n",
    "rbprog.cfg = AttrDict(attrs['config'])\n",
    "rbprog.calib_order = attrs['calib_order']\n",
    "\n",
    "data_12_x = rbprog.analyze(fit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xpts_x = file_x_q1q2['xpts']\n",
    "xpts_x = data_12_x['xpts']\n",
    "\n",
    "n_x = len(np.asarray(xpts_x)[0])\n",
    "\n",
    "# pop_12 = np.asarray(file_x_q1q2['poplns_2q'])\n",
    "pop_12 = np.asarray(data_12_x['poplns_2q'])\n",
    "\n",
    "pop_dict_x_12 = {}\n",
    "\n",
    "pop_dict_x_12['avg'] = {}\n",
    "pop_dict_x_12['err'] = {}\n",
    "\n",
    "for idx, state in enumerate(state_name_str):\n",
    "    pop_dict_x_12['avg'][state] = pop_12[:, :, idx].mean(axis=1)\n",
    "    pop_dict_x_12['err'][state] = pop_12[:, :, idx].std(axis=1)/np.sqrt(n_x)\n",
    "\n",
    "popln_subspace_avg_x_12=  np.sum([pop_dict_x_12['avg'][state] for state in state_subspace], axis=0)\n",
    "_pop_temp = np.zeros_like(pop_12[:, :, 0])\n",
    "for idx, state in enumerate(state_name_str):\n",
    "    if state in state_subspace:\n",
    "        _pop_temp += pop_12[:, :, idx]\n",
    "popln_subspace_err_x_12 = np.std(_pop_temp, axis=1)/np.sqrt(n_x)\n",
    "\n",
    "\n",
    "popln_eg_x_12 = pop_dict_x_12['avg']['eg']\n",
    "popln_eg_renorm_x_12 = popln_eg_x_12/popln_subspace_avg_x_12\n",
    "\n",
    "idx_eg = state_name_str.index('eg')\n",
    "_pop_temp = pop_12[:, :, idx_eg]\n",
    "popln_eg_err_x_12 = np.std(_pop_temp, axis=1)/np.sqrt(n_x)\n",
    "\n",
    "idx_eg = state_name_str.index('eg')\n",
    "idx_gf = state_name_str.index('gf')\n",
    "_pop_temp = pop_12[:, :, idx_eg]/(pop_12[:, :, idx_eg] + pop_12[:, :, idx_gf])\n",
    "popln_eg_renorm_err_x_12 = np.std(_pop_temp, axis=1)/np.sqrt(n_x)\n",
    "\n",
    "popln_not_erase_x_12 = 1 - np.sum([pop_dict_x_12['avg'][state] for state in state_erasure], axis=0)\n",
    "_pop_temp = np.zeros_like(pop_12[:, :, 0])\n",
    "for idx, state in enumerate(state_name_str):\n",
    "    if state in state_erasure:\n",
    "        _pop_temp += pop_12[:, :, idx]\n",
    "popln_not_erase_err_x_12 = np.std(_pop_temp, axis=1)/np.sqrt(n_x)\n",
    "\n",
    "x_rb_x_12 = np.unique(xpts_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting everything together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RB Q3/Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = ([0, 0, 0], [1, np.inf, np.inf])\n",
    "\n",
    "cut = slice(0, 30)\n",
    "\n",
    "# popt_13, pcov = opt.curve_fit(fit, x_rb_13[cut], popln_subspace_avg_13[cut], sigma=popln_subspace_err_13[cut], absolute_sigma=True, p0=[0.99, 0.01, 0.01], maxfev=10000, xtol=1e-15, ftol=1e-15, bounds=bounds)\n",
    "popt_13, pcov = opt.curve_fit(fit, x_rb_13, popln_subspace_avg_13, sigma=popln_subspace_err_13, absolute_sigma=True, p0=[0.99, 0.01, 0.01], maxfev=10000, xtol=1e-15, ftol=1e-15, bounds=bounds)\n",
    "perr_13 = np.sqrt(np.diag(pcov))\n",
    "\n",
    "popt2_13, pcov2 = opt.curve_fit(fit, x_rb_13[cut], popln_eg_renorm_13[cut], p0=[0.8, 0.01, 0.01], sigma=popln_eg_renorm_err_13[cut], absolute_sigma=True, maxfev=10000, xtol=1e-15, ftol=1e-15, bounds=bounds)\n",
    "perr2_13 = np.sqrt(np.diag(pcov2))\n",
    "\n",
    "if len(state_erasure) > 0:\n",
    "    popt3_13, pcov3 = opt.curve_fit(fit, x_rb_13[cut], popln_not_erase_13[cut], p0=[0.8, 0.01, 0.01], sigma=popln_not_erase_err_13[cut], absolute_sigma=True, maxfev=10000, xtol=1e-15, ftol=1e-15, bounds=bounds)\n",
    "    perr3_13 = np.sqrt(np.diag(pcov3))\n",
    "else:\n",
    "    popt3_13 = None\n",
    "    perr3_13 = None\n",
    "\n",
    "# Alternative to fitting eg/subspace: fit to double exponential \"survival probability\"\n",
    "popt4_13, pcov4 = meas.fitting.fitrb_l1_l2(x_rb_13, popln_eg_13, p1=popt_13[0], sigma=popln_eg_err_13)\n",
    "perr4_13 = np.sqrt(np.diag(pcov4))\n",
    "\n",
    "# Alternative to fitting eg/subspace: fit to single exponential \"survival probability\"\n",
    "popt5_13, pcov5 = opt.curve_fit(fit, x_rb_13, popln_eg_13, sigma=popln_eg_err_13, absolute_sigma=True, p0=[0.99, 0.01, 0.01], maxfev=10000, xtol=1e-15, ftol=1e-15, bounds=bounds)\n",
    "perr5_13 = np.sqrt(np.diag(pcov5))\n",
    "\n",
    "x_rb_fit_x_12 = np.linspace(0, np.max(x_rb_x_12), 1000)\n",
    "y_fit_pop_x_12 = fit(x_rb_fit_x_12, *popt_x_12)\n",
    "y_fit_leak_x_12 = fit(x_rb_fit_x_12, *popt2_x_12)\n",
    "y_fit_erase_x_12 = fit(x_rb_fit_x_12, *popt3_x_12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IRB Q3/Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RB Q2/Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = ([0, 0, 0], [1, np.inf, np.inf])\n",
    "\n",
    "cut = slice(0, 30)\n",
    "\n",
    "# popt_12, pcov = opt.curve_fit(fit, x_rb_12[cut], popln_subspace_avg_12[cut], sigma=popln_subspace_err_12[cut], absolute_sigma=True, p0=[0.99, 0.01, 0.01], maxfev=10000, xtol=1e-15, ftol=1e-15, bounds=bounds)\n",
    "popt_12, pcov = opt.curve_fit(fit, x_rb_12, popln_subspace_avg_12, sigma=popln_subspace_err_12, absolute_sigma=True, p0=[0.99, 0.01, 0.01], maxfev=10000, xtol=1e-15, ftol=1e-15, bounds=bounds)\n",
    "perr_12 = np.sqrt(np.diag(pcov))\n",
    "\n",
    "popt2_12, pcov2 = opt.curve_fit(fit, x_rb_12[cut], popln_eg_renorm_12[cut], p0=[0.8, 0.01, 0.01], sigma=popln_eg_renorm_err_12[cut], absolute_sigma=True, maxfev=10000, xtol=1e-15, ftol=1e-15, bounds=bounds)\n",
    "perr2_12 = np.sqrt(np.diag(pcov2))\n",
    "\n",
    "if len(state_erasure) > 0:\n",
    "    popt3_12, pcov3 = opt.curve_fit(fit, x_rb_12[cut], popln_not_erase_12[cut], p0=[0.8, 0.01, 0.01], sigma=popln_not_erase_err_12[cut], absolute_sigma=True, maxfev=10000, xtol=1e-15, ftol=1e-15, bounds=bounds)\n",
    "    perr3_12 = np.sqrt(np.diag(pcov3))\n",
    "else:\n",
    "    popt3_12 = None\n",
    "    perr3_12 = None\n",
    "\n",
    "# Alternative to fitting eg/subspace: fit to double exponential \"survival probability\"\n",
    "popt4_12, pcov4 = meas.fitting.fitrb_l1_l2(x_rb_12, popln_eg_12, p1=popt_12[0], sigma=popln_eg_err_12)\n",
    "perr4_12 = np.sqrt(np.diag(pcov4))\n",
    "\n",
    "# Alternative to fitting eg/subspace: fit to single exponential \"survival probability\"\n",
    "popt5_12, pcov5 = opt.curve_fit(fit, x_rb_12, popln_eg_12, sigma=popln_eg_err_12, absolute_sigma=True, p0=[0.99, 0.01, 0.01], maxfev=10000, xtol=1e-15, ftol=1e-15, bounds=bounds)\n",
    "perr5_12 = np.sqrt(np.diag(pcov5))\n",
    "\n",
    "x_rb_fit_12 = np.linspace(0, np.max(x_rb_12), 1000)\n",
    "y_fit_pop_12 = fit(x_rb_fit_12, *popt_12)\n",
    "y_fit_leak_12 = fit(x_rb_fit_12, *popt2_12)\n",
    "y_fit_surv_12 = meas.fitting.rb_decay_l1_l2(x_rb_fit_12, popt_12[0], *popt4_12)\n",
    "y_fit_surv_single_12 = fit(x_rb_fit_12, *popt5_12)\n",
    "\n",
    "if len(state_erasure) > 0:\n",
    "    y_fit_erase_12 = fit(x_rb_fit_12, *popt3_12)\n",
    "else:\n",
    "    y_fit_erase_12 = None\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Q2/Q1 RB\")\n",
    "plt.plot(x_rb_12, popln_subspace_avg_12, 'o', label='Subspace')\n",
    "plt.plot(x_rb_fit_12, y_fit_pop_12)\n",
    "plt.plot(x_rb_12, popln_eg_renorm_12, 'o', label='eg/subspace')\n",
    "plt.plot(x_rb_fit_12, y_fit_leak_12)\n",
    "plt.plot(x_rb_12, popln_eg_12, 'o', label='eg')\n",
    "plt.plot(x_rb_fit_12, y_fit_surv_12)\n",
    "plt.plot(x_rb_fit_12, y_fit_surv_single_12)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IRB Q2/Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = ([0, 0, 0], [1, np.inf, np.inf])\n",
    "cut = slice(0, 30)\n",
    "\n",
    "# popt_x_12, pcov = opt.curve_fit(fit, x_rb_x_12[cut], popln_subspace_avg_x_12[cut], sigma=popln_subspace_err_x_12[cut], absolute_sigma=True, p0=[0.99, 0.01, 0.01], maxfev=10000, xtol=1e-15, ftol=1e-15, bounds=bounds)\n",
    "popt_x_12, pcov = opt.curve_fit(fit, x_rb_x_12, popln_subspace_avg_x_12, sigma=popln_subspace_err_x_12, absolute_sigma=True, p0=[0.99, 0.01, 0.01], maxfev=10000, xtol=1e-15, ftol=1e-15, bounds=bounds)\n",
    "perr_x_12 = np.sqrt(np.diag(pcov))\n",
    "\n",
    "popt2_x_12, pcov2 = opt.curve_fit(fit, x_rb_x_12[cut], popln_eg_renorm_x_12[cut], p0=[0.8, 0.01, 0.01], sigma=popln_eg_renorm_err_x_12[cut], absolute_sigma=True, maxfev=10000, xtol=1e-15, ftol=1e-15, bounds=bounds)\n",
    "perr2_x_12 = np.sqrt(np.diag(pcov2))\n",
    "\n",
    "if len(state_erasure) > 0:\n",
    "    popt3_x_12, pcov3 = opt.curve_fit(fit, x_rb_x_12[cut], popln_not_erase_x_12[cut], p0=[0.8, 0.01, 0.01], sigma=popln_not_erase_err_x_12[cut], absolute_sigma=True, maxfev=10000, xtol=1e-15, ftol=1e-15, bounds=bounds)\n",
    "    perr3_x_12 = np.sqrt(np.diag(pcov3))\n",
    "else:\n",
    "    popt3_x_12 = None\n",
    "    perr3_x_12 = None\n",
    "\n",
    "# Alternative to fitting eg/subspace: fit to double exponential \"survival probability\"\n",
    "popt4_x_12, pcov4 = meas.fitting.fitrb_l1_l2(x_rb_x_12, popln_eg_x_12, p1=popt_x_12[0], sigma=popln_eg_err_x_12)\n",
    "perr4_x_12 = np.sqrt(np.diag(pcov4))\n",
    "\n",
    "# Alternative to fitting eg/subspace: fit to single exponential \"survival probability\"\n",
    "popt5_x_12, pcov5 = opt.curve_fit(fit, x_rb_x_12, popln_eg_x_12, sigma=popln_eg_err_x_12, absolute_sigma=True, p0=[0.99, 0.01, 0.01], maxfev=10000, xtol=1e-15, ftol=1e-15, bounds=bounds)\n",
    "perr5_x_12 = np.sqrt(np.diag(pcov5))\n",
    "\n",
    "x_rb_fit_x_12 = np.linspace(0, np.max(x_rb_x_12), 1000)\n",
    "y_fit_pop_x_12 = fit(x_rb_fit_x_12, *popt_x_12)\n",
    "y_fit_leak_x_12 = fit(x_rb_fit_x_12, *popt2_x_12)\n",
    "y_fit_surv_x_12 = meas.fitting.rb_decay_l1_l2(x_rb_fit_x_12, popt_x_12[0], *popt4_x_12)\n",
    "y_fit_surv_single_x_12 = fit(x_rb_fit_x_12, *popt5_x_12)\n",
    "\n",
    "if len(state_erasure) > 0:\n",
    "    y_fit_erase_x_12 = fit(x_rb_fit_x_12, *popt3_x_12)\n",
    "else:\n",
    "    y_fit_erase_x_12 = None\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Q2/Q1 IRB\")\n",
    "plt.plot(x_rb_x_12, popln_subspace_avg_x_12, 'o', label='Subspace')\n",
    "plt.plot(x_rb_fit_x_12, y_fit_pop_x_12)\n",
    "plt.plot(x_rb_x_12, popln_eg_renorm_x_12, 'o', label='eg/subspace')\n",
    "plt.plot(x_rb_fit_x_12, y_fit_leak_x_12)\n",
    "plt.plot(x_rb_x_12, popln_eg_x_12, 'o', label='eg')\n",
    "plt.plot(x_rb_fit_x_12, y_fit_surv_x_12)\n",
    "plt.plot(x_rb_fit_x_12, y_fit_surv_single_x_12)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process the fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_X_per_clifford = 2.167 / 2 # got this by counting the average number of X/2's per Clifford gate in the group, divide by 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_errors(\n",
    "    popt, popt2, popt3, popt4, popt5,\n",
    "    perr, perr2, perr3, perr4, perr5,\n",
    "    popt_x, popt2_x, popt3_x, popt4_x, popt5_x,\n",
    "    perr_x, perr2_x, perr3_x, perr4_x, perr5_x,\n",
    "    d=2,\n",
    "    get_p2_from=0, # process using 0. popt2, 1. popt4, 2. popt5 for the lambda2 value\n",
    "    ):\n",
    "\n",
    "    lambda1 = popt[0]\n",
    "    A = popt[2]\n",
    "    lambda2 = [popt2[0], popt4[3], popt5[0]][get_p2_from]\n",
    "    lambda2_err = [perr2[0], perr4[3], perr5[0]][get_p2_from]\n",
    "    L = (1 - A)*(1 - lambda1)\n",
    "    Lerr = L*np.sqrt((perr[2]/(1 - A))**2 + (perr[0]/(1 - lambda1))**2)\n",
    "\n",
    "    if popt3 is not None:\n",
    "        p3 = popt3[0]\n",
    "        erase = (1 - popt3[2])*(1 - popt3[0])\n",
    "        erase_err  = erase*np.sqrt((perr3[2]/(1 - popt3[2]))**2 + (perr3[0]/(1 - popt3[0]))**2)\n",
    "    else:\n",
    "        erase = 0\n",
    "        erase_err = 0\n",
    "\n",
    "    lambda1_x = popt_x[0]\n",
    "    A_x = popt_x[2]\n",
    "    lambda2_x = [popt2_x[0], popt4_x[3], popt5_x[0]][get_p2_from]\n",
    "    lambda2_x_err = [perr2_x[0], perr4_x[3], perr5_x[0]][get_p2_from]\n",
    "    L_int = (1 - A_x)*(1 - lambda1_x)\n",
    "    Lerr_x = L_int*np.sqrt((perr_x[2]/(1 - A_x))**2 + (perr_x[0]/(1 - lambda1_x))**2)\n",
    "\n",
    "    if popt3_x is not None:\n",
    "        p3_x = popt3_x[0]\n",
    "        erase_x = (1 - popt3_x[2])*(1 - popt3_x[0])\n",
    "        erase_err_x = erase_x*np.sqrt((perr3_x[2]/(1 - popt3_x[2]))**2 + (perr3_x[0]/(1 - popt3_x[0]))**2)\n",
    "    else:\n",
    "        erase_x = 0\n",
    "        erase_err_x = 0 \n",
    "\n",
    "    if get_p2_from != 2:\n",
    "        err = 1 - (1/d) * ((d-1)*lambda2 + 1-L) # this is the RB error with a leakage contribution\n",
    "        err_err = np.sqrt((d-1)**2 / d**2 * lambda2_err**2 + Lerr**2 / d**2)\n",
    "        err_int = 1 - (1/d) * ((d-1)*lambda2_x + 1-L_int)\n",
    "        err_int_err = np.sqrt((d-1)**2 / d**2 * lambda2_x_err**2 + Lerr_x**2 / d**2)\n",
    "    else: # for fitting the eg directly, leakage is accounted for in the error already?\n",
    "        err = 1 - (1/d) * ((d-1)*lambda2 + 1) # this is the RB error with a leakage contribution\n",
    "        err_err = (d-1) / d * lambda2_err\n",
    "        err_int = 1 - (1/d) * ((d-1)*lambda2_x + 1)\n",
    "        err_int_err = (d-1) / d * lambda2_x_err\n",
    "\n",
    "    err_X = 1 - (1 - err_int) / (1 - err)\n",
    "    # err_bound1 = (d-1)*(np.abs(lambda2 - lambda2_x/lambda2) + (1 - lambda2))/d\n",
    "    # err_bound2 = 2*(d**2 - 1)*(1 - lambda2)/(lambda2*d**2) + 4*np.sqrt((1 - lambda2)*(d**2 - 1)/d)\n",
    "    # err_X_err = np.min([err_bound1, err_bound2])\n",
    "    err_X_err = np.sqrt((err_int_err**2/(1-err)**2) + (1/(err-1) - (err-err_int)/(1-err)**2)**2 * err_err**2)\n",
    "\n",
    "\n",
    "    L_tot = 1 - (1 - L_int) / (1 - L)\n",
    "    erase_tot = 1 - (1 - erase_x)*(1 - erase)\n",
    "\n",
    "    L_tot_err = np.sqrt(Lerr_x**2/(1 - L)**2 + Lerr**2*L_int**2/(1 - L)**4)\n",
    "\n",
    "    erase_tot_err = np.sqrt(erase_err_x**2/(1 - erase)**2 + erase_err**2*erase_x**2/(1 - erase)**4)\n",
    "\n",
    "    err_tot = err_X\n",
    "    err_tot_err = err_X_err\n",
    "\n",
    "    F = 1 - err_tot  \n",
    "    F_err = err_tot_err\n",
    "\n",
    "    results_dict = dict(\n",
    "        err=err,\n",
    "        err_err=err_err,\n",
    "\n",
    "        err_X=err_X,\n",
    "        err_X_err=err_X_err,\n",
    "\n",
    "        err_int=err_int,\n",
    "        err_int_err=err_int_err,\n",
    "\n",
    "        L=L,\n",
    "        Lerr=Lerr,\n",
    "\n",
    "        L_int=L_int,\n",
    "        Lerr_x=Lerr_x,\n",
    "\n",
    "        L_tot=L_tot,\n",
    "        L_tot_err=L_tot_err,\n",
    "\n",
    "        erase=erase,\n",
    "        erase_err=erase_err,\n",
    "        \n",
    "        erase_x=erase_x,\n",
    "        erase_err_x=erase_err_x,\n",
    "\n",
    "        erase_tot=erase_tot,\n",
    "        erase_tot_err=erase_tot_err,\n",
    "        F=F,\n",
    "        F_err=F_err,\n",
    "    )\n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_12 = get_errors(\n",
    "    popt_12, popt2_12, popt3_12, popt4_12, popt5_12,\n",
    "    perr_12, perr2_12, perr3_12, perr4_12, perr5_12,\n",
    "    popt_x_12, popt2_x_12, popt3_x_12, popt4_x_12, popt5_x_12,\n",
    "    perr_x_12, perr2_x_12, perr3_x_12, perr4_x_12, perr5_x_12,\n",
    "    get_p2_from=get_p2_from,\n",
    ")\n",
    "\n",
    "print(\"All values in percent\")\n",
    "print(\"Q2/Q1\")\n",
    "print('Error reference per X: %.3f +/- %.3f' % (results_12['err'] / avg_X_per_clifford*100, results_12['err_err'] / avg_X_per_clifford*100))\n",
    "print('Error interleaved per X: %.3f +/- %.3f' % (results_12['err_X'] / (avg_X_per_clifford+1)*100, results_12['err_X_err'] / (avg_X_per_clifford+1)*100))\n",
    "print('Leakage error from reference per X: %.3f +/- %.3f' % (results_12['L'] / avg_X_per_clifford*100, results_12['Lerr'] / avg_X_per_clifford*100))\n",
    "print('Leakage error from interleaved per X: %.3f +/- %.3f' % (results_12['L_int'] / avg_X_per_clifford*100, results_12['Lerr_x'] / avg_X_per_clifford*100))\n",
    "print('Erasure from reference: %.3f +/- %.3f' % (results_12['erase'] / avg_X_per_clifford*100, results_12['erase_err'] / avg_X_per_clifford*100))\n",
    "print('Erasure from interleaved: %.3f +/- %.3f' % (results_12['erase_x'] / avg_X_per_clifford*100, results_12['erase_err_x'] / avg_X_per_clifford*100))\n",
    "print('Leakage per swap overall: %.3f +/- %.3f' % (results_12['L_tot']*100, results_12['L_tot_err']*100))\n",
    "print('Erasure per swap overall: %.3f +/- %.3f' %(results_12['erase_tot']*100, results_12['erase_tot_err']*100))\n",
    "print('Fidelity:', 100*results_12['F'], '+/-', results_12['F_err']*100)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_13 = get_errors(\n",
    "    popt_13, popt2_13, popt3_13, popt4_13, popt5_13,\n",
    "    perr_13, perr2_13, perr3_13, perr4_13, perr5_13,\n",
    "    popt_x_13, popt2_x_13, popt3_x_13, popt4_x_13, popt5_x_13,\n",
    "    perr_x_13, perr2_x_13, perr3_x_13, perr4_x_13, perr5_x_13,\n",
    "    get_p2_from=get_p2_from,\n",
    ")\n",
    "\n",
    "print(\"All values in percent\")\n",
    "print(\"Q3/Q1\")\n",
    "print('Error reference: %.3f +/- %.3f' % (results_13['err']*100, results_13['err_err']*100))\n",
    "print('Error interleaved: %.3f +/- %.3f' % (results_13['err_X']*100, results_13['err_X_err']*100))\n",
    "print('Leakage error from reference: %.3f +/- %.3f' % (results_13['L']*100, results_13['Lerr']*100))\n",
    "print('Leakage error from interleaved: %.3f +/- %.3f' % (results_13['L_int']*100, results_13['Lerr_x']*100))\n",
    "print('Erasure from reference: %.3f +/- %.3f' % (results_13['erase']*100, results_13['erase_err']*100))\n",
    "print('Erasure from interleaved: %.3f +/- %.3f' % (results_13['erase_x']*100, results_13['erase_err_x']*100))\n",
    "print('Leakage per swap overall: %.3f +/- %.3f' % (results_13['L_tot']*100, results_13['L_tot_err']*100))\n",
    "print('Erasure per swap overall: %.3f +/- %.3f' %(results_13['erase_tot']*100, results_13['erase_tot_err']*100))\n",
    "print('Fidelity:', 100*results_13['F'], '+/-', results_13['F_err']*100)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(5, 3))\n",
    "\n",
    "irb_color = '#8A9A69'\n",
    "rb_color = '#E9A464'\n",
    "\n",
    "log_scale = False\n",
    "\n",
    "data = popln_eg_renorm_12\n",
    "if log_scale:\n",
    "    rescale_factor = 0.5/(np.max(data) - np.min(data))\n",
    "    rescale_baseline = np.min(data)\n",
    "else:\n",
    "    rescale_factor = 1\n",
    "    rescale_baseline = 0\n",
    "\n",
    "data = popln_eg_renorm_12\n",
    "data_err = popln_eg_renorm_err_12\n",
    "# rescaled_y = (data - rescale_baseline)*rescale_factor + 0.5\n",
    "rescaled_y = (data - rescale_baseline)*rescale_factor\n",
    "# print(data, rescale_baseline, rescale_factor)\n",
    "ax[0].errorbar(x_rb_12, rescaled_y, yerr=rescale_factor*data_err, fmt='o', markersize=3.5, label='reference', color=rb_color, linestyle='', zorder=0)\n",
    "data = popln_eg_renorm_x_12\n",
    "data_err = popln_eg_renorm_err_x_12\n",
    "# rescaled_y = (data - rescale_baseline)*rescale_factor + 0.5\n",
    "rescaled_y = (data - rescale_baseline)*rescale_factor\n",
    "# print(data, rescale_baseline, rescale_factor)\n",
    "ax[0].errorbar(x_rb_x_12, rescaled_y, yerr=rescale_factor*data_err, fmt='o', markersize=3.5, label='interleaved', color=irb_color,\n",
    "                linestyle='', zorder=0)\n",
    "\n",
    "ax[0].set_title('Input - Output 1')\n",
    "if log_scale:\n",
    "    ax[0].set_yscale('log')\n",
    "\n",
    "data = y_fit_leak_12\n",
    "# rescaled_y = (data - rescale_baseline)*rescale_factor + 0.5\n",
    "rescaled_y = (data - rescale_baseline)*rescale_factor\n",
    "ax[0].plot(x_rb_fit_12, rescaled_y, '--', color=rb_color, zorder=1)\n",
    "data = y_fit_leak_x_12\n",
    "# rescaled_y = (data - rescale_baseline)*rescale_factor + 0.5\n",
    "rescaled_y = (data - rescale_baseline)*rescale_factor\n",
    "ax[0].plot(x_rb_fit_x_12, rescaled_y, '--', color=irb_color, zorder=1)\n",
    "\n",
    "\n",
    "data = popln_eg_renorm_13\n",
    "if log_scale:\n",
    "    rescale_factor = 0.5/(np.max(data) - np.min(data))\n",
    "    rescale_baseline = np.min(data)\n",
    "else:\n",
    "    rescale_factor = 1\n",
    "    rescale_baseline = 0\n",
    "\n",
    "data = popln_eg_renorm_13\n",
    "data_err = popln_eg_renorm_err_13\n",
    "# rescaled_y = (data - rescale_baseline)*rescale_factor + 0.5\n",
    "rescaled_y = (data - rescale_baseline)*rescale_factor\n",
    "ax[1].errorbar(x_rb_13, rescaled_y , yerr=rescale_factor*data_err, fmt='o', markersize=3.5, label='reference', color=rb_color, linestyle='', zorder=0)\n",
    "data = popln_eg_renorm_x_13\n",
    "data_err = popln_eg_renorm_err_x_13\n",
    "# rescaled_y = (data - rescale_baseline)*rescale_factor + 0.5\n",
    "rescaled_y = (data - rescale_baseline)*rescale_factor\n",
    "ax[1].errorbar(x_rb_x_13, rescaled_y, yerr=rescale_factor*data_err, fmt='o', markersize=3.5, label='interleaved', color=irb_color,\n",
    "                linestyle='', zorder=0)\n",
    "\n",
    "ax[1].set_title('Input - Output 2')\n",
    "if log_scale:\n",
    "    ax[1].set_yscale('log')\n",
    "\n",
    "data = y_fit_leak_13\n",
    "# rescaled_y = (data - rescale_baseline)*rescale_factor + 0.5\n",
    "rescaled_y = (data - rescale_baseline)*rescale_factor\n",
    "ax[1].plot(x_rb_fit_13, rescaled_y, '--', color=rb_color, zorder=1)\n",
    "data = y_fit_leak_x_13\n",
    "# rescaled_y = (data - rescale_baseline)*rescale_factor + 0.5\n",
    "rescaled_y = (data - rescale_baseline)*rescale_factor\n",
    "ax[1].plot(x_rb_fit_x_13, rescaled_y, '--', color=irb_color, zorder=1)\n",
    "\n",
    "# set yticks\n",
    "\n",
    "ax[0].set_yticks([0.0, 0.5, 1])\n",
    "ax[1].set_yticks([0.5, 1])\n",
    "# for i in range(2):\n",
    "#     ax[i].set_yticks([0.0, 0.5, 1])\n",
    "#     # ax[i].set_ylim([0.4, 1.1])\n",
    "#     ax[i].set_ylim([-0.05, 1.05])\n",
    "\n",
    "\n",
    "for item in ([ax[0].title, ax[0].xaxis.label, ax[0].yaxis.label] +\n",
    "             ax[0].get_xticklabels() + ax[0].get_yticklabels()):\n",
    "    item.set_fontsize(12)\n",
    "\n",
    "\n",
    "for item in ([ax[1].title, ax[1].xaxis.label, ax[1].yaxis.label] +\n",
    "             ax[1].get_xticklabels() + ax[1].get_yticklabels()):\n",
    "    item.set_fontsize(12)\n",
    "\n",
    "ax[0].set_ylabel('Fidelity')\n",
    "\n",
    "ax[0].set_xlabel('Number of Cliffords')\n",
    "ax[1].set_xlabel('Number of Cliffords')\n",
    "\n",
    "ax[0].legend(fontsize=10, loc='upper right')\n",
    "ax[1].legend(fontsize=10, loc='upper right')\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.savefig('fidelity_q1q2_q1q3.pdf')\n",
    "fig.savefig('fidelity_q1q2_q1q3.jpg', dpi=300)\n",
    "fig.savefig('fidelity_q1q2_q1q3.svg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popln_not_erase_12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2, ax2 = plt.subplots(2, 1, figsize=(4, 3), sharex=True)\n",
    "fig3, ax3 = plt.subplots(2, 1, figsize=(4, 3), sharex=True)\n",
    "\n",
    "ax2[0].errorbar(x_rb_12, popln_subspace_avg_12, yerr=popln_subspace_err_12, fmt='o', label='Q1-Q2', color='#516c96',\n",
    "                linestyle='', zorder=0)\n",
    "ax2[0].errorbar(x_rb_x_12, popln_subspace_avg_x_12, yerr=popln_subspace_err_x_12, fmt='o', label='Q1-Q2', color='#9c6a8c',\n",
    "                linestyle='', zorder=0)\n",
    "\n",
    "ax3[0].errorbar(x_rb_12, popln_not_erase_12, yerr=popln_not_erase_err_12, fmt='o', label='Q1-Q3', color='#516c96',\n",
    "                linestyle='', zorder=0)\n",
    "ax3[0].errorbar(x_rb_x_12, popln_not_erase_x_12, yerr=popln_not_erase_err_x_12, fmt='o', label='Q1-Q3', color='#9c6a8c',\n",
    "                linestyle='', zorder=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ax2[0].plot(x_rb_fit_12, y_fit_pop_12, color='black', zorder=1)\n",
    "ax2[0].plot(x_rb_fit_x_12, y_fit_pop_x_12, color='black', zorder=1)\n",
    "\n",
    "ax3[0].plot(x_rb_fit_12  , y_fit_erase_12, color='black', zorder=1)\n",
    "ax3[0].plot(x_rb_fit_x_12, y_fit_erase_x_12, color='black', zorder=1)\n",
    "\n",
    "ax2[1].errorbar(x_rb_13, popln_subspace_avg_13, yerr=popln_subspace_err_13, fmt='o', label='reference', color='#516c96',\n",
    "                linestyle='', zorder=0)\n",
    "\n",
    "ax2[1].errorbar(x_rb_x_13, popln_subspace_avg_x_13, yerr=popln_subspace_err_x_13, fmt='o', label='interleaved', color='#9c6a8c',\n",
    "                linestyle='', zorder=0)\n",
    "\n",
    "\n",
    "ax3[1].errorbar(x_rb_13, popln_not_erase_13, yerr=popln_not_erase_err_13, fmt='o', label='reference', color='#516c96',\n",
    "                linestyle='', zorder=0)\n",
    "\n",
    "ax3[1].errorbar(x_rb_x_13, popln_not_erase_x_13, yerr=popln_not_erase_err_x_13, fmt='o', label='interleaved', color='#9c6a8c',\n",
    "                linestyle='', zorder=0)\n",
    "\n",
    "\n",
    "ax2[1].plot(x_rb_fit_13, y_fit_pop_13, color='black', zorder=1)\n",
    "ax2[1].plot(x_rb_fit_x_13, y_fit_pop_x_13, color='black', zorder=1)\n",
    "\n",
    "ax3[1].plot(x_rb_fit_13, y_fit_erase_13, color='black', zorder=1)\n",
    "ax3[1].plot(x_rb_fit_x_13, y_fit_erase_x_13, color='black', zorder=1)\n",
    "\n",
    "\n",
    "# set yticks\n",
    "\n",
    "for i in range(2):\n",
    "    ax2[i].set_yticks([0, 1.1])\n",
    "    ax2[i].set_ylim([0, 1.1])\n",
    "    ax2[i].hlines(1, 0, 100, linestyle='--', color='black', zorder=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot on one panel the subspace and its fit for RB and IRB and on the other panel the eg/(eg+gf) and its fit for RB and IRB\n",
    "\n",
    "# fig, ax = plt.subplots(1, 2, figsize=(7, 4))\n",
    "\n",
    "\n",
    "\n",
    "# text_leak = '$L_{ref}$ =' + '{:.3f} $\\pm$ {:.3f} %'.format(L*100, Lerr*100) + '\\n' + '$L_{int}$ =' + '{:.3f} $\\pm$ {:.3f} %'.format(L_x*100, Lerr_x*100) + '\\n' + '$L_{tot}$ =' + '{:.3f} $\\pm$ {:.3f} %'.format(L_tot*100, L_tot_err*100)\n",
    "\n",
    "# text_eg = '$r_{cliff}$ =' + '{:.2f} $\\pm$ {:.2f} %'.format(err*100, err_err*100) + '\\n' + '$r_{int}$ =' + '{:.2f} $\\pm$ {:.2f} %'.format(err_int*100, err_int_err*100) + '\\n' + '$F_{tot}$ =' + '{:.2f} $\\pm$ {:.2f} %'.format(F*100, F_err*100)\n",
    "\n",
    "# ax[0].text(0.5, 0.1, text_leak, horizontalalignment='center', verticalalignment='center', transform=ax[0].transAxes)\n",
    "# ax[1].text(0.5, 0.1, text_eg, horizontalalignment='center', verticalalignment='center', transform=ax[1].transAxes)\n",
    "\n",
    "# ax[0].errorbar(np.unique(xpts), popln_subspace_avg, yerr=popln_subspace_std, fmt='o-',\n",
    "#                 label='Reference', color='#445fab', linestyle='', alpha=0.7)\n",
    "# ax[0].errorbar(np.unique(xpts_x), popln_subspace_avg_x, yerr=popln_subspace_std_x,\n",
    "#                 fmt='o-', label='Interlieved', color='#ab4d44', linestyle='', alpha=0.7)\n",
    "\n",
    "# ax[0].plot(x_rb_fit, y_fit_pop, color='black')\n",
    "# ax[0].plot(x_fit_rb_x, y_fit_pop_x, color='black')\n",
    "\n",
    "# ax[1].errorbar(np.unique(xpts), popln_eg_renorm, yerr=popln_eg_renorm_err, fmt='o-', \n",
    "#                color='#445fab', alpha=0.7, linestyle='')\n",
    "# ax[1].errorbar(np.unique(xpts_x), popln_eg_renorm_x, yerr=popln_eg_renorm_err_x, fmt='o-', \n",
    "#                color='#ab4d44', alpha=0.7, linestyle='')\n",
    "\n",
    "# ax[1].plot(x_rb_fit, y_fit_leak, color='black')\n",
    "# ax[1].plot(x_fit_rb_x, y_fit_leak_x, color='black')\n",
    "\n",
    "\n",
    "\n",
    "# ax[0].set_ylim([0.1, 1])\n",
    "# ax[1].set_ylim([0.1, 1])\n",
    "\n",
    "# ax[0].set_ylabel('Population')\n",
    "# ax[0].set_xlabel('Number of Clifford')\n",
    "\n",
    "# ax[1].set_ylabel('Population')\n",
    "# ax[1].set_xlabel('Number of Clifford')\n",
    "\n",
    "# ax[0].legend()\n",
    "# ax[0].set_title('Subspace leakage')\n",
    "# ax[1].set_title('Subspace fidelity')\n",
    "\n",
    "# fig.tight_layout()\n",
    "\n",
    "# fig.savefig('fidelity_q1q3.png', dpi=300)\n",
    "# fig.savefig('fidelity_q1q3.pdf', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = '00000_SimultaneousRBEgGf.h5'\n",
    "folder = 'data_240617'\n",
    "file = h5py.File(folder+'/'+file_name, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(file.keys())\n",
    "\n",
    "l1 = np.asarray(file['l1'])\n",
    "l2 = np.asarray(file['l2'])\n",
    "# popln_eg = np.asarray(file['popln_eg'])\n",
    "popln_eg_avg = np.asarray(file['popln_eg_avg'])\n",
    "popln_eg_std = np.asarray(file['popln_eg_std'])\n",
    "# popln_subspace = np.asarray(file['popln_subspace'])\n",
    "popln_subspace_avg = np.asarray(file['popln_subspace_avg'])\n",
    "popln_subspace_std = np.asarray(file['popln_subspace_std'])\n",
    "xpts = np.asarray(file['xpts'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(x, p, B, A):\n",
    "    return B*p**x + A\n",
    "\n",
    "def fit2(x, p1, B0, p2, A0, C0):\n",
    "    return A0 + B0*p1**x + C0*p2**x\n",
    "\n",
    "\n",
    "bounds_1 = ([0, 0, 0], [1, np.inf, 1])\n",
    "\n",
    "popt, pcov = opt.curve_fit(fit, np.unique(xpts), popln_subspace_avg,\n",
    "                            p0=[0.99, 0.01, 0.01], maxfev=10000, xtol=1e-15, ftol=1e-15, bounds=bounds_1)\n",
    "# use the fitted p to fit the subspace \n",
    "\n",
    "_fit2 = lambda x, B0, p2, A0, C0: fit2(x, popt[0], B0, p2, A0, C0)\n",
    "\n",
    "# we need 0<A0<A, 0<C0<1, 0<A0+B0+C0<1\n",
    "bounds = ([0, 0, 0, 0], [1, 1, popt[2], 1])\n",
    "popt2, pcov2 = opt.curve_fit(_fit2, np.unique(xpts), popln_eg_avg, maxfev=10000, xtol=1e-15, ftol=1e-15, bounds=bounds)\n",
    "popt3, pcov3 = opt.curve_fit(fit, np.unique(xpts), popln_eg_avg, maxfev=10000, xtol=1e-15, ftol=1e-15,  p0=[0.99, 0.01, 0.01])\n",
    "\n",
    "\n",
    "\n",
    "perr = np.sqrt(np.diag(pcov))\n",
    "perr2 = np.sqrt(np.diag(pcov2))\n",
    "perr3 = np.sqrt(np.diag(pcov3))\n",
    "L_ref = (1 -popt[2])*(1 - popt[0])\n",
    "L_ref_err = L_ref*np.sqrt((perr[2]*(1 - popt[2]))**2 + (perr[0]*(1 - popt[0]))**2)\n",
    "\n",
    "d = 2\n",
    "p1 = popt[0]\n",
    "p1_err = perr[0]\n",
    "p2 = popt2[1]\n",
    "p2_err = perr2[1]\n",
    "F = 1/d*((d -1)*p2 + 1 - L_ref)\n",
    "\n",
    "print('p1 subspace: ', p1, '+/-', p1_err)\n",
    "print('p2 eg: ', p2, '+/-', p2_err)\n",
    "print('L_ref: ', L_ref, '+/-', L_ref_err)\n",
    "print('F: ', F)\n",
    "print('popt', popt)\n",
    "print('perr', perr)\n",
    "print('popt2', popt2)\n",
    "print('perr2', perr2)\n",
    "\n",
    "p = p2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### try using lmfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(x, p, B):\n",
    "    return B*p**x\n",
    "\n",
    "def fit2(x, p1, B0, p2, A0, C0):\n",
    "    return A0 + B0*p1**x + C0*p2**x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subspace fititng\n",
    "\n",
    "p_true = create_params(p = p, B = popt2[0])\n",
    " \n",
    "def residual(pars, x, data=None):\n",
    "    p = pars['p']\n",
    "    B = pars['B']\n",
    "    model = fit(x, p, B)\n",
    "    if data is None:\n",
    "        return model\n",
    "    return model - data\n",
    "\n",
    "fit_params = create_params(p=dict(value=p, min=0, max=1),\n",
    "                                      B=dict(value=popt2[0], min=0, max=1))\n",
    "\n",
    "x = np.unique(xpts)\n",
    "data = popln_subspace_avg\n",
    "out = minimize(residual, fit_params, args=(x,), kws={'data': data})\n",
    "fit = residual(out.params, x)\n",
    "\n",
    "report_fit(out, modelpars=p_true, correl_mode='table')\n",
    "\n",
    "p1 = out.params['p'].value\n",
    "p1_err = out.params['p'].stderr\n",
    "\n",
    "# eg fitting \n",
    "\n",
    "_fit2 = lambda x, B0, p2, A0, C0: fit2(x, p1, B0, p2, A0, C0)\n",
    "\n",
    "\n",
    "def residual2(pars, x, data=None):\n",
    "    p2 = pars['p2']\n",
    "    B0 = pars['B0']\n",
    "    A0 = pars['A0']\n",
    "    C0 = pars['C0']\n",
    "    model = _fit2(x, B0, p2, A0, C0)\n",
    "    if data is None:\n",
    "        return model\n",
    "    return model - data\n",
    "\n",
    "fit_params2 = create_params(p2=dict(value=popt2[1], min=0, max=1),\n",
    "                                        B0=dict(value=popt2[0], min=-np.inf, max=np.inf),\n",
    "                                        A0=dict(value=0, min=-np.inf, max=np.inf),\n",
    "                                        C0=dict(value=0, min=-np.inf, max=np.inf))\n",
    "\n",
    "x = np.unique(xpts)\n",
    "data = popln_eg_avg\n",
    "\n",
    "out2 = minimize(residual2, fit_params2, args=(x,), kws={'data': data})\n",
    "fit2 = residual2(out2.params, x)\n",
    "\n",
    "report_fit(out2, modelpars=popt2, correl_mode='table')\n",
    "\n",
    "p2 = out2.params['p2'].value\n",
    "p2_err = out2.params['p2'].stderr\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # extract the fitted parameters\n",
    "# p1_bis = result.params['p'].value\n",
    "# _fit2 = lambda x, B0, p2, A0, C0: fit2(x, p1_bis, B0, p2, A0, C0)\n",
    "# fit_model2 = Model(_fit2)\n",
    "# params2 = fit_model2.make_params(B0=popt2[0], p2=popt2[1], A0=popt2[2], C0=popt2[3])\n",
    "# result2 = fit_model2.fit(popln_eg_avg, params2, x=np.unique(xpts))\n",
    "\n",
    "# print('First fit: ')\n",
    "# print(result.fit_report())\n",
    "# print('------------------------')\n",
    "# print('Second fit: ')\n",
    "# print(result2.fit_report())\n",
    "# p2_bis = result2.params['p2'].value\n",
    "\n",
    "# L_ref_bis = (1 -p2)*(1 - p1)\n",
    "# L_ref_bis_err = L_ref_bis*np.sqrt((p2_err*(1 - p2))**2 + (p1_err*(1 - p1))**2)\n",
    "# print('L_ref_bis: ', L_ref_bis, '+/-', L_ref_bis_err)\n",
    "\n",
    "# plot the second fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(7, 4))\n",
    "\n",
    "# ax[0].plot(xpts, popln_eg, 'o-', color='#445fab', linestyle='none', alpha=0.1)\n",
    "# ax[1].plot(xpts, popln_subspace, 'o-', color='#ab4d44', linestyle='none', alpha=0.1)\n",
    "ax[0].errorbar(np.unique(xpts), popln_eg_avg, yerr=popln_eg_std, fmt='-o', color='#445fab', label='', markersize=5, linestyle='none')\n",
    "ax[1].errorbar(np.unique(xpts), popln_subspace_avg, yerr=popln_subspace_std, fmt='-o', color='#ab4d44', label='Subspace', markersize=5, linestyle='none')\n",
    "\n",
    "x = np.linspace(0, np.max(xpts), 1000)\n",
    "y = fit(x, *popt)\n",
    "y_plus = fit(x, popt[0] + perr[0], popt[1] + perr[1], popt[2] + perr[2])\n",
    "y_minus = fit(x, popt[0] - perr[0], popt[1] - perr[1], popt[2] - perr[2])\n",
    "ax[1].plot(x, y, color='black', zorder=10)\n",
    "ax[1].fill_between(x, y_minus, y_plus, color='black', alpha=0.2, zorder=10)\n",
    "# add text for the leackage and p and there errorbars\n",
    "textstr = '\\n'.join((\n",
    "    r'$L=%.2f \\pm %.2f$' % (L_ref*100, L_ref_err*100),\n",
    "    r'$p1=%.2f \\pm %.2f$' % (popt[0], perr[0])))\n",
    "props = dict(boxstyle='round', alpha=0)\n",
    "# place a text box in lower left in axes coords\n",
    "ax[1].text(0.05, 0.05, textstr, transform=ax[1].transAxes, fontsize=10)\n",
    "\n",
    "# popt2 = np.insert(popt2, 1, popt[0])\n",
    "y2 = _fit2(x, *popt2)\n",
    "y3 = fit(x, *popt3)\n",
    "y2_plus = _fit2(x, popt2[0] + perr2[0], popt2[1], popt2[2] + perr2[2], popt2[3] + perr2[3])\n",
    "y2_minus = _fit2(x, popt2[0] - perr2[0], popt2[1], popt2[2] - perr2[2], popt2[3] - perr2[3])\n",
    "ax[0].plot(x, y2, color='black', zorder=10)\n",
    "ax[0].plot(x, y3, color='grey', zorder=10)\n",
    "ax[0].fill_between(x, y2_minus, y2_plus, color='black', alpha=0.2, zorder=10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ax[1].plot(x, y2, color='black')\n",
    "\n",
    "ax[0].set_ylabel('Population')\n",
    "ax[1].set_ylabel('Population')\n",
    "ax[0].set_xlabel('Number of Cliffords')\n",
    "ax[1].set_xlabel('Number of Cliffords')\n",
    "\n",
    "ax[0].legend()\n",
    "ax[1].legend()\n",
    "\n",
    "# ax[0].set_yscale('log')\n",
    "# ax[1].set_yscale('log')\n",
    "\n",
    "\n",
    "# display the fit parameters in the plot\n",
    "\n",
    "# textstr = '\\n'.join((\n",
    "#     r'$A=%.2f$' % (popt[1], ),\n",
    "#     r'$B=%.2f$' % (popt[2], ),\n",
    "#     r'$p=%.2f$' % (popt[0], )))\n",
    "# props = dict(boxstyle='round', alpha=0.5)\n",
    "# ax.text(0.05, 0.95, textstr, transform=ax.transAxes, fontsize=14,\n",
    "#         verticalalignment='top', bbox=props)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IRB X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = '00001_SimultaneousRBEgGf.h5'\n",
    "folder = 'data_240617'\n",
    "file = h5py.File(folder+'/'+file_name, 'r')\n",
    "file.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(file.keys())\n",
    "\n",
    "l1 = np.asarray(file['l1'])\n",
    "l2 = np.asarray(file['l2'])\n",
    "# popln_eg = np.asarray(file['popln_eg'])\n",
    "popln_eg_avg = np.asarray(file['popln_eg_avg'])\n",
    "popln_eg_std = np.asarray(file['popln_eg_std'])\n",
    "# popln_subspace = np.asarray(file['popln_subspace'])\n",
    "popln_subspace_avg = np.asarray(file['popln_subspace_avg'])\n",
    "popln_subspace_std = np.asarray(file['popln_subspace_std'])\n",
    "xpts = np.asarray(file['xpts'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(x, p, B, A):\n",
    "    return B*p**x + A\n",
    "\n",
    "def fit2(x, p1, B0, p2, A0, C0):\n",
    "    return A0 + B0*p1**x + C0*p2**x\n",
    "\n",
    "\n",
    "bounds_1 = ([0, 0, 0], [1, np.inf, 1])\n",
    "\n",
    "popt, pcov = opt.curve_fit(fit, np.unique(xpts), popln_subspace_avg,\n",
    "                            p0=[0.99, 0.01, 0.01], maxfev=10000, xtol=1e-15, ftol=1e-15, bounds=bounds_1)\n",
    "# use the fitted p to fit the subspace \n",
    "\n",
    "_fit2 = lambda x, B0, p2, A0, C0: fit2(x, popt[0], B0, p2, A0, C0)\n",
    "\n",
    "# we need 0<A0<A, 0<C0<1, 0<A0+B0+C0<1\n",
    "bounds = ([0, 0, 0, 0], [1, 1, popt[2], 1])\n",
    "popt2, pcov2 = opt.curve_fit(_fit2, np.unique(xpts), popln_eg_avg, maxfev=10000, xtol=1e-15, ftol=1e-15, bounds=bounds)\n",
    "popt3, pcov3 = opt.curve_fit(fit, np.unique(xpts), popln_eg_avg, maxfev=10000, xtol=1e-15, ftol=1e-15,  p0=[0.99, 0.01, 0.01])\n",
    "\n",
    "\n",
    "\n",
    "perr = np.sqrt(np.diag(pcov))\n",
    "perr2 = np.sqrt(np.diag(pcov2))\n",
    "perr3 = np.sqrt(np.diag(pcov3))\n",
    "Lc = (1 -popt[2])*(1 - popt[0])\n",
    "Lc_err = Lc*np.sqrt((perr[2]*(1 - popt[2]))**2 + (perr[0]*(1 - popt[0]))**2)\n",
    "\n",
    "d = 2\n",
    "p1 = popt[0]\n",
    "p1_err = perr[0]\n",
    "p2 = popt2[1]\n",
    "p2_err = perr2[1]\n",
    "\n",
    "print('p1 subspace: ', p1, '+/-', p1_err)\n",
    "print('p2 eg: ', p2, '+/-', p2_err)\n",
    "print('Lc: ', Lc, '+/-', Lc_err)\n",
    "\n",
    "\n",
    "pc = p2\n",
    "E_1 = (d-1)*(np.abs(p - pc/p) + (1-p))/d\n",
    "E_2 = 2*(d**2 - 1)*(1-p)/(p*d**2) + 4*np.sqrt((1-p)*(d**2-1))/p\n",
    "rx_err = np.min([E_1, E_2])\n",
    "\n",
    "rx = (d-1)*(1 - pc/p)/d\n",
    "Lx = 1 - (1 - Lc)/(1 - L_ref)\n",
    "Fx = 1 - rx - Lx\n",
    "\n",
    "print('rx:{} +/- {}'.format(rx, rx_err))\n",
    "print('Lx: {}'.format(Lx))\n",
    "print('Fx: {}'.format(Fx))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### try using lmfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = fit_model.make_params(p=popt[0], B=popt[1], A=popt[2])\n",
    "result_irb = fit_model.fit(popln_subspace_avg, params, x=np.unique(xpts))\n",
    "\n",
    "# extract the fitted parameters\n",
    "p1_irb_bis = result_irb.params['p'].value\n",
    "_fit2 = lambda x, B0, p2, A0, C0: fit2(x, p2, B0, p2, A0, C0)\n",
    "fit_model2 = Model(_fit2)\n",
    "params2 = fit_model2.make_params(B0=popt2[0], p2=popt2[1], A0=popt2[2], C0=popt2[3])\n",
    "result2 = fit_model2.fit(popln_eg_avg, params2, x=np.unique(xpts))\n",
    "\n",
    "print('First fit: ')\n",
    "print(result.fit_report())\n",
    "print('------------------------')\n",
    "print('Second fit: ')\n",
    "print(result2.fit_report())\n",
    "p2_bis = result2.params['p2'].value\n",
    "\n",
    "L_ref_bis = (1 -p2)*(1 - p1)\n",
    "L_ref_bis_err = L_ref_bis*np.sqrt((p2_err*(1 - p2))**2 + (p1_err*(1 - p1))**2)\n",
    "print('L_ref_bis: ', L_ref_bis, '+/-', L_ref_bis_err)\n",
    "\n",
    "# plot the second fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(7, 4))\n",
    "\n",
    "# ax[0].plot(xpts, popln_eg, 'o-', color='#445fab', linestyle='none', alpha=0.1)\n",
    "# ax[1].plot(xpts, popln_subspace, 'o-', color='#ab4d44', linestyle='none', alpha=0.1)\n",
    "ax[0].errorbar(np.unique(xpts), popln_eg_avg, yerr=popln_eg_std, fmt='-o', color='#445fab', label='', markersize=5, linestyle='none')\n",
    "ax[1].errorbar(np.unique(xpts), popln_subspace_avg, yerr=popln_subspace_std, fmt='-o', color='#ab4d44', label='Subspace', markersize=5, linestyle='none')\n",
    "\n",
    "x = np.linspace(0, np.max(xpts), 1000)\n",
    "y = fit(x, *popt)\n",
    "y_plus = fit(x, popt[0] + perr[0], popt[1] + perr[1], popt[2] + perr[2])\n",
    "y_minus = fit(x, popt[0] - perr[0], popt[1] - perr[1], popt[2] - perr[2])\n",
    "ax[1].plot(x, y, color='black', zorder=10)\n",
    "ax[1].fill_between(x, y_minus, y_plus, color='black', alpha=0.2, zorder=10)\n",
    "# add text for the leackage and p and there errorbars\n",
    "textstr = '\\n'.join((\n",
    "    r'$L=%.2f \\pm %.2f$' % (L*100, Lerr*100),\n",
    "    r'$p1=%.2f \\pm %.2f$' % (popt[0], perr[0])))\n",
    "props = dict(boxstyle='round', alpha=0)\n",
    "# place a text box in lower left in axes coords\n",
    "ax[1].text(0.05, 0.05, textstr, transform=ax[1].transAxes, fontsize=10)\n",
    "\n",
    "# popt2 = np.insert(popt2, 1, popt[0])\n",
    "y2 = _fit2(x, *popt2)\n",
    "y3 = fit(x, *popt3)\n",
    "y2_plus = _fit2(x, popt2[0] + perr2[0], popt2[1], popt2[2] + perr2[2], popt2[3] + perr2[3])\n",
    "y2_minus = _fit2(x, popt2[0] - perr2[0], popt2[1], popt2[2] - perr2[2], popt2[3] - perr2[3])\n",
    "ax[0].plot(x, y2, color='black', zorder=10)\n",
    "ax[0].plot(x, y3, color='grey', zorder=10)\n",
    "ax[0].fill_between(x, y2_minus, y2_plus, color='black', alpha=0.2, zorder=10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ax[1].plot(x, y2, color='black')\n",
    "\n",
    "ax[0].set_ylabel('Population')\n",
    "ax[1].set_ylabel('Population')\n",
    "ax[0].set_xlabel('Number of Cliffords')\n",
    "ax[1].set_xlabel('Number of Cliffords')\n",
    "\n",
    "ax[0].legend()\n",
    "ax[1].legend()\n",
    "\n",
    "# ax[0].set_yscale('log')\n",
    "# ax[1].set_yscale('log')\n",
    "\n",
    "\n",
    "# display the fit parameters in the plot\n",
    "\n",
    "# textstr = '\\n'.join((\n",
    "#     r'$A=%.2f$' % (popt[1], ),\n",
    "#     r'$B=%.2f$' % (popt[2], ),\n",
    "#     r'$p=%.2f$' % (popt[0], )))\n",
    "# props = dict(boxstyle='round', alpha=0.5)\n",
    "# ax.text(0.05, 0.95, textstr, transform=ax.transAxes, fontsize=14,\n",
    "#         verticalalignment='top', bbox=props)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = '00002_SimultaneousRBEgGf.h5'\n",
    "folder = 'data_240617'\n",
    "file = h5py.File(folder+'/'+file_name, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poplns_2q = np.asarray(file['poplns_2q'])\n",
    "xpts = np.asarray(file['xpts'])\n",
    "\n",
    "x = np.unique(xpts)\n",
    "\n",
    "ordering = ['gg', 'ge', 'eg', 'ee', 'gf', 'ef']\n",
    "p = {'avg':{}, 'std':{}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, key in enumerate(ordering):\n",
    "    p['avg'][key] = np.average(poplns_2q[:,:,i], axis=1)\n",
    "    p['std'][key] = np.std(poplns_2q[:,:,i], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(5, 4))\n",
    "\n",
    "\n",
    "for key in ordering:\n",
    "    ax.errorbar(x, p['avg'][key], yerr=p['std'][key], fmt='o-', label=key)\n",
    "\n",
    "ax.set_ylabel('Population')\n",
    "ax.set_xlabel('Number of Cliffords')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "p_eg_bare = poplns_2q[:,:,np.argwhere(np.array(ordering) == 'eg')[0,0]]\n",
    "p_gf_bare = poplns_2q[:,:,np.argwhere(np.array(ordering) == 'gf')[0,0]]\n",
    "\n",
    "p_subspace= p_eg_bare + p_gf_bare\n",
    "p_subspace_avg = np.average(p_subspace, axis=1)\n",
    "p_subspace_std = np.std(p_subspace, axis=1)\n",
    "\n",
    "_p_fid = p_eg_bare \n",
    "_p_fid_avg = np.average(_p_fid, axis=1)/p_subspace_avg\n",
    "_p_fid_std = np.std(_p_fid, axis=1)/p_subspace_avg\n",
    "\n",
    "p_fid = p_eg_bare / (p_eg_bare + p_gf_bare)\n",
    "p_fid_avg = np.average(p_fid, axis=1)\n",
    "p_fid_std = np.std(p_fid, axis=1)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 4))\n",
    "ax.errorbar(x, p_subspace_avg, yerr=p_subspace_std, fmt='o-', label='Subspace bis')\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 4))\n",
    "# ax.errorbar(x, p['avg']['fid'], yerr=p['std']['fid'], fmt='o-', label='Fidelity')\n",
    "ax.errorbar(x, p_fid_avg, yerr=p_fid_std, fmt='o-', label='True', alpha=0.7)\n",
    "ax.errorbar(x, _p_fid_avg, yerr=_p_fid_std, fmt='o-', label='False', alpha=0.7)\n",
    "\n",
    "ax.set_ylim([0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the covariance of p_eg and p_gf\n",
    "\n",
    "p_eg = poplns_2q[:,:,np.argwhere(np.array(ordering) == 'eg')[0,0]]\n",
    "p_gf = poplns_2q[:,:,np.argwhere(np.array(ordering) == 'gf')[0,0]]\n",
    "\n",
    "cov = np.cov(p_eg, p_gf)\n",
    "\n",
    "print(cov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monitoring results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qubits = [0,1,2,3]\n",
    "check_ef  = [False, False, True, True]\n",
    "folder = 'data_240617'\n",
    "\n",
    "param_plot = ['t1', 't2', 'freq', 'temp']\n",
    "\n",
    "fig_ge, ax_ge = plt.subplots(len(qubits), len(param_plot)-1, figsize=(7, 10), sharey=True)\n",
    "fig_ef, ax_ef = plt.subplots(np.sum(check_ef), len(param_plot)-1, figsize=(7, 5), sharey=True)\n",
    "idx_ef = 0\n",
    "\n",
    "# plot histograms of the parameters for each qubit\n",
    "\n",
    "# also extract the mean and std of the data and store it in dictionary\n",
    "\n",
    "qb_data = {}\n",
    "\n",
    "for idxq, qubit_i in enumerate(qubits):\n",
    "    file_name = 'qubit_' + str(qubit_i) + '_data.npz'\n",
    "    data = np.load(folder+'/'+file_name)\n",
    "    keys = data.keys()\n",
    "    for idxp, param in enumerate(param_plot):\n",
    "        if param != 'temp':\n",
    "            _p = param + '_ge'\n",
    "            _perr = _p + '_err'\n",
    "            # takeout the data equal to 0 \n",
    "            p = data[_p]\n",
    "            perr = data[_perr]\n",
    "\n",
    "            idx = np.argwhere(p != 0).flatten()\n",
    "            p = p[idx]\n",
    "            perr = perr[idx]\n",
    "\n",
    "            if param !='freq':\n",
    "                idx = np.argwhere(p<500).flatten()\n",
    "                p = p[idx]\n",
    "                perr = perr[idx] \n",
    "\n",
    "            if param == 'freq': p = p/1e3\n",
    "\n",
    "            ax_ge[idxq, idxp].hist(p, bins=20, alpha=0.9, label='ge')\n",
    "            # add the mean and std of the data\n",
    "            ax_ge[idxq, idxp].axvline(np.mean(p), color='black', linestyle='--')\n",
    "            ax_ge[idxq, idxp].axvline(np.mean(p) + np.std(p), color='black', linestyle='--')\n",
    "            ax_ge[idxq, idxp].axvline(np.mean(p) - np.std(p), color='black', linestyle='--')\n",
    "\n",
    "            dict_key = 'qubit_' + str(qubit_i) + '_' + _p\n",
    "            qb_data[dict_key] = {'mean': np.mean(p), 'std': np.std(p)}\n",
    "\n",
    "            if check_ef[idxq]:\n",
    "            \n",
    "                _p = param + '_ef'\n",
    "                _perr = _p + '_err'\n",
    "                p = data[_p]\n",
    "                perr = data[_perr]\n",
    "                idx = np.argwhere(p != 0).flatten()\n",
    "\n",
    "                p = p[idx]\n",
    "                perr = perr[idx]\n",
    "\n",
    "                if param !='freq':\n",
    "                    idx = np.argwhere(p<500)\n",
    "                    p = p[idx]\n",
    "                    perr = perr[idx] \n",
    "\n",
    "                if param == 'freq': p = p/1e3\n",
    "                ax_ef[idx_ef, idxp].hist(p, bins=20, alpha=0.9, label='ef')\n",
    "                # add the mean and std of the data\n",
    "                ax_ef[idx_ef, idxp].axvline(np.mean(p), color='black', linestyle='--')\n",
    "                ax_ef[idx_ef, idxp].axvline(np.mean(p) + np.std(p), color='black', linestyle='--')\n",
    "                ax_ef[idx_ef, idxp].axvline(np.mean(p) - np.std(p), color='black', linestyle='--')\n",
    "\n",
    "                dict_key = 'qubit_' + str(qubit_i) + '_' + _p\n",
    "                qb_data[dict_key] = {'mean': np.mean(p), 'std': np.std(p)}\n",
    "\n",
    "            if qubit_i == qubits[-1]:\n",
    "                # capitalize the first letter of the parameter\n",
    "                param = param.capitalize()\n",
    "                ax_ge[idxq, idxp].set_xlabel(param)\n",
    "                ax_ge[idxq, idxp].set_ylabel('Counts')\n",
    "\n",
    "                if check_ef[idxq]:\n",
    "                    param = param.capitalize()\n",
    "                    ax_ef[idx_ef, idxp].set_xlabel(param)\n",
    "                    ax_ef[idx_ef, idxp].set_ylabel('Counts')\n",
    "\n",
    "        else:\n",
    "            print('temp')\n",
    "            T = data['temp']\n",
    "            dict_key = 'qubit_' + str(qubit_i) + '_temp'\n",
    "            qb_data[dict_key] = {'mean': T, 'std': 0}\n",
    "            \n",
    "\n",
    "\n",
    "    if check_ef[idxq]: idx_ef += 1\n",
    "\n",
    "fig_ge.tight_layout()\n",
    "fig_ge.suptitle(r'$|ge\\rangle$ subspace')\n",
    "fig_ge.subplots_adjust(top=0.95)\n",
    "\n",
    "fig_ef.tight_layout()\n",
    "fig_ef.suptitle(r'$|ef\\rangle$ subspace')\n",
    "fig_ef.subplots_adjust(top=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qb_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qb_data['qubit_0_freq_ge'] - qb_data['qubit_0_freq_ef']\n",
    "# qb_data['qubit_1_freq_ge'] - qb_data['qubit_1_freq_ef']\n",
    "print(qb_data['qubit_2_freq_ge']['mean'] - qb_data['qubit_2_freq_ef']['mean'])\n",
    "print(qb_data['qubit_3_freq_ge']['mean'] - qb_data['qubit_3_freq_ef']['mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import qutip as qt \n",
    "import scipy.constants as cst\n",
    "import itertools\n",
    "from TomoAnalysis import TomoAnalysis\n",
    "from PulseSequence import PulseSequence\n",
    "from QSwitch import QSwitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_qubit_subpace(psi, qram): \n",
    "\n",
    "    cutoffs = qram.cutoffs\n",
    "    # define the qubit basis states\n",
    "    cutoff_range = [np.arange(0, 2) for c in cutoffs]\n",
    "\n",
    "    nb_qubit = len(cutoffs)\n",
    "    psi_basis = []\n",
    "    cutoff_all  = np.array(np.meshgrid(*cutoff_range)).T.reshape(-1, len(cutoff_range))\n",
    "    psi_basis = []\n",
    "    for c in cutoff_all:\n",
    "        state = qram.level_nums_to_name(c)\n",
    "        ket = qram.state(state)\n",
    "        psi_basis.append(ket)\n",
    "\n",
    "    psi_qubit_basis = []\n",
    "    for c in cutoff_all:\n",
    "        ket_2q = qt.tensor([qt.basis(2, c[i]) for i in range(len(cutoffs))])\n",
    "        psi_qubit_basis.append(ket_2q)\n",
    "\n",
    "    # project the state onto the qubit subspace\n",
    "\n",
    "\n",
    "    dims = psi.dims\n",
    "    psi_proj = 0*psi_qubit_basis[0]\n",
    "\n",
    "\n",
    "    if dims[0] != dims[1]:\n",
    "        for ii in range(len(psi_basis)):\n",
    "            psi_proj += psi.overlap(psi_basis[ii])*psi_qubit_basis[ii]\n",
    "    else:\n",
    "        psi_proj = psi_proj*psi_proj.dag()\n",
    "        for ii in range(len(psi_basis)):\n",
    "            for jj in range(len(psi_basis)):\n",
    "                coeff = (psi_basis[ii].dag()*psi*psi_basis[jj]).tr()\n",
    "                psi_proj += coeff*psi_qubit_basis[ii]*psi_qubit_basis[jj].dag()\n",
    "\n",
    "\n",
    "    return psi_proj/psi_proj.norm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "qubit_freqs = None\n",
    "alphas = None\n",
    "\n",
    "\n",
    "EJs = None\n",
    "ECs = None\n",
    "\n",
    "q0_zz = 4107.855190582331*1e-3\n",
    "q1_zz = 3443.976854588233*1e-3\n",
    "\n",
    "rotating_frame = False\n",
    "\n",
    "# qubit_eg = np.array([4109.26018927, 3457.69704279, 4761.99805965, 4380.60688399])*1e-3\n",
    "# alphas = np.array([-230.63575032, -101.35143276, -191.14210906, -174.22297538])*1e-3\n",
    "# g_vec = np.array([52.43448118394156, 54.846432562535114, 43.51980836018165, 4.927733842829573, 2.6387744519352285, 6.384197707619073])*1e-3\n",
    "\n",
    "\n",
    "qubit_eg = np.array([4106.14726604, 3456.6701284,  4759.78012348, 4378.87093728])*1e-3\n",
    "alphas = np.array([-229.56066202, -102.2334172, -191.13666666, -174.38074586])*1e-3\n",
    "g_vec = np.array([52.41151277832647, 54.227062360553134, 44.64043444983635, 3.612297112825406, 2.5619407686581845, 6.059085014586995])*1e-3\n",
    "T_vec = np.array([71.35656729, 54.85995099, 63.33430112, 85.82535118])*1e-3*1e-9 # rescale to ghz\n",
    "\n",
    "gs = np.zeros((4,4))\n",
    "gs[0,1] = g_vec[0]\n",
    "gs[1,2] = g_vec[1]\n",
    "gs[1,3] = g_vec[2]\n",
    "gs[0,2] = g_vec[3]\n",
    "gs[0,3] = g_vec[4]\n",
    "gs[2,3] = g_vec[5]\n",
    "\n",
    "\n",
    "gs = gs + gs.T\n",
    "\n",
    "T1_eg = np.array([53.549092929369884, 87.89632398316435, 43.84166327646582, 59.10401847636979])*1e6\n",
    "T1_ef = np.array([20, 20, 40.22012003969479, 26.52349966633519])*1e6\n",
    "T2_eg = np.array([23.748977711686997, 47.04661359778277, 50.571425216342796, 34.80171657984668])*1e6\n",
    "T2_ef = np.array([20, 20, 26.139422179794657, 13.342533012189866])*1e6\n",
    "\n",
    "\n",
    "\n",
    "decay_rate_eg = 1/T1_eg\n",
    "decay_rate_ef = 1/T1_ef\n",
    "\n",
    "dephasing_rate_eg = 1/T2_eg - decay_rate_eg/2\n",
    "dephasing_rate_ef = 1/T2_ef - decay_rate_ef/2\n",
    "\n",
    "\n",
    "\n",
    "crosstalk = np.eye(4)*1\n",
    "\n",
    "t_rise = 20# ns\n",
    "\n",
    "cutoffs = [3, 4, 4, 4]\n",
    "isCavity = [False, False, False, False]\n",
    "decay = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accounting for the decay channels \n",
    "# T1_eg \n",
    "\n",
    "if decay: \n",
    "\n",
    "    c_ops_list = []\n",
    "\n",
    "    for k in range(len(cutoffs)):\n",
    "\n",
    "        # ket = qram.state('gggg')\n",
    "        # str_bra = 'g'*k + 'e' + 'g'*(3-k)\n",
    "        # bra = qram.state(str_bra)\n",
    "        ket = qt.basis(cutoffs[k], 0)\n",
    "        bra = qt.basis(cutoffs[k], 1).dag()\n",
    "        tensor = [ket*bra if i == k else qt.qeye(cutoffs[i]) for i in range(len(cutoffs))]\n",
    "        c_ops = [np.sqrt(decay_rate_eg[k])*qt.tensor(tensor)]\n",
    "        c_ops_list.append(c_ops[0])\n",
    "\n",
    "    # T1_fe\n",
    "        \n",
    "    for k in range(len(cutoffs)):\n",
    "\n",
    "        ket =qt.basis(cutoffs[k], 1)\n",
    "        bra = qt.basis(cutoffs[k], 2).dag()\n",
    "        tensor = [ket*bra if i == k else qt.qeye(cutoffs[i]) for i in range(len(cutoffs))]\n",
    "        c_ops = [np.sqrt(decay_rate_ef[k])*qt.tensor(tensor)]\n",
    "        c_ops_list.append(c_ops[0])\n",
    "\n",
    "    # dephasing eg, their is a factor 2 in the dephasing rate for consistency\n",
    "        \n",
    "    for k in range(len(cutoffs)):\n",
    "\n",
    "        ket = qt.basis(cutoffs[k], 1)\n",
    "        tensor = [ket*ket.dag() if i == k else qt.qeye(cutoffs[i]) for i in range(len(cutoffs))]\n",
    "        c_ops = [np.sqrt(2*dephasing_rate_eg[k])*qt.tensor(tensor)]\n",
    "        c_ops_list.append(c_ops[0])\n",
    "\n",
    "    # dephasing fe\n",
    "        \n",
    "    for k in range(len(cutoffs)):\n",
    "        \n",
    "        ket = qt.basis(cutoffs[k], 2)\n",
    "        tensor = [ket*ket.dag() if i == k else qt.qeye(cutoffs[i]) for i in range(len(cutoffs))]\n",
    "        c_ops = [np.sqrt(2*dephasing_rate_ef[k])*qt.tensor(tensor)]\n",
    "        c_ops_list.append(c_ops[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "qram = QSwitch(\n",
    "    EJs=EJs,\n",
    "    ECs=ECs,\n",
    "    gs=gs,\n",
    "    qubit_freqs=qubit_eg,\n",
    "    alphas=alphas,\n",
    "    cutoffs=cutoffs,\n",
    "    isCavity=isCavity,\n",
    "    crosstalk=crosstalk\n",
    ")\n",
    "\n",
    "qubit_freqs = qram.qubit_freqs\n",
    "alphas = qram.alphas\n",
    "print('qubit freqs (GHz)', *qubit_freqs)\n",
    "print('alphas (GHz)', *alphas)\n",
    "print('aprox sideband freqs (GHz)', (2*qubit_freqs[2] + alphas[2] - qubit_freqs[1], 2*qubit_freqs[3] + alphas[3] - qubit_freqs[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial state if thermal population \n",
    "nth = 1/(np.exp(cst.h*qubit_eg/(cst.k*T_vec))-1)\n",
    "\n",
    "rho_vec = []\n",
    "\n",
    "for idx, c in enumerate(cutoffs):\n",
    "    rho = qt.thermal_dm(c, nth[idx])\n",
    "    rho_vec.append(rho)\n",
    "\n",
    "rho_init = qt.tensor(rho_vec)\n",
    "\n",
    "# define the X and X/2 gates for q1 and q2\n",
    "\n",
    "X = qt.qip.operations.rx(np.pi)*1j\n",
    "X2 = qt.qip.operations.rx(np.pi/2)*1j\n",
    "print(X2)\n",
    "\n",
    "# expands the dimension to account for the actuall cutoffs\n",
    "\n",
    "_X = X.full()\n",
    "print(_X)\n",
    "_X2 = X2.full()\n",
    "print(_X2)\n",
    "\n",
    "X0 = np.eye(cutoffs[0], dtype=complex)\n",
    "X1 = np.eye(cutoffs[1], dtype=complex)\n",
    "X2 = np.eye(cutoffs[2], dtype=complex)\n",
    "X3 = np.eye(cutoffs[3], dtype=complex)\n",
    "X0_2 = np.eye(cutoffs[0], dtype=complex)\n",
    "X1_2 = np.eye(cutoffs[1], dtype=complex)\n",
    "X2_2 = np.eye(cutoffs[2], dtype=complex)\n",
    "X3_2 = np.eye(cutoffs[3], dtype=complex)\n",
    "\n",
    "\n",
    "X0[:2, :2] = _X\n",
    "X1[:2, :2] = _X\n",
    "X2[:2, :2] = _X\n",
    "X3[:2, :2] = _X\n",
    "X0_2[:2, :2] = _X2\n",
    "print(X0_2)\n",
    "X1_2[:2, :2] = _X2\n",
    "X2_2[:2, :2] = _X2\n",
    "X3_2[:2, :2] = _X2\n",
    "\n",
    "X0 = qt.Qobj(X0)\n",
    "X1 = qt.Qobj(X1)\n",
    "X2 = qt.Qobj(X2)\n",
    "X3 = qt.Qobj(X3)\n",
    "X0_2 = qt.Qobj(X0_2)\n",
    "print(X0_2)\n",
    "X1_2 = qt.Qobj(X1_2)\n",
    "X2_2 = qt.Qobj(X2_2)\n",
    "X3_2 = qt.Qobj(X3_2)\n",
    "\n",
    "# tensor the X gates with the identity to match the cutoffs\n",
    "\n",
    "X0 = qt.tensor(X0, qt.qeye(cutoffs[1]), qt.qeye(cutoffs[2]), qt.qeye(cutoffs[3]))\n",
    "X1 = qt.tensor(qt.qeye(cutoffs[0]), X1, qt.qeye(cutoffs[2]), qt.qeye(cutoffs[3]))\n",
    "X2 = qt.tensor(qt.qeye(cutoffs[0]), qt.qeye(cutoffs[1]), X2, qt.qeye(cutoffs[3]))\n",
    "X3 = qt.tensor(qt.qeye(cutoffs[0]), qt.qeye(cutoffs[1]), qt.qeye(cutoffs[2]), X3)\n",
    "X0_2 = qt.tensor(X0_2, qt.qeye(cutoffs[1]), qt.qeye(cutoffs[2]), qt.qeye(cutoffs[3]))\n",
    "X1_2 = qt.tensor(qt.qeye(cutoffs[0]), X1_2, qt.qeye(cutoffs[2]), qt.qeye(cutoffs[3]))\n",
    "X2_2 = qt.tensor(qt.qeye(cutoffs[0]), qt.qeye(cutoffs[1]), X2_2, qt.qeye(cutoffs[3]))\n",
    "X3_2 = qt.tensor(qt.qeye(cutoffs[0]), qt.qeye(cutoffs[1]), qt.qeye(cutoffs[2]), X3_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "tomo = TomoAnalysis(nb_qubits=4)\n",
    "\n",
    "X = qt.qip.operations.rx(np.pi)*1j\n",
    "I = qt.qeye(2)\n",
    "calib_order = tomo.calib_order\n",
    "rho_calib = {}\n",
    "rho_init_calib = project_qubit_subpace(rho_init, qram)\n",
    "psi0 = qram.state('gggg')\n",
    "psi0 = project_qubit_subpace(psi0, qram)\n",
    "psi_proj = {}\n",
    "\n",
    "for idx, o in enumerate(calib_order):\n",
    "    U = []\n",
    "    for idx_s, s in enumerate(o):\n",
    "        if s =='e':\n",
    "            U.append(X)\n",
    "        else:\n",
    "            U.append(I)\n",
    "    U = qt.tensor(U)\n",
    "    rho_calib[o] = U*rho_init_calib*U.dag()\n",
    "    psi_proj[o] = U*psi0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "calib_mat = np.zeros((len(calib_order), len(calib_order)), dtype=complex)\n",
    "\n",
    "for idx, o in enumerate(calib_order):\n",
    "    for jdx, o2 in enumerate(calib_order):\n",
    "        calib_mat[idx, jdx] = np.real(np.abs(rho_calib[o].overlap(psi_proj[o2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho_init_dict = {}\n",
    "\n",
    "rho_init_dict['gggg'] = rho_init\n",
    "rho_init_dict['eggg'] = X0*rho_init*X0.dag()\n",
    "rho_init_dict['gegg'] = X1*rho_init*X1.dag()\n",
    "rho_init_dict['eegg'] = X1*X0*rho_init*X0.dag()*X1.dag()\n",
    "rho_init_dict['+ggg'] = X0_2*rho_init*X0_2.dag()\n",
    "rho_init_dict['g+gg'] = X1_2*rho_init*X1_2.dag()\n",
    "rho_init_dict['++gg'] = X1_2*X0_2*rho_init*X0_2.dag()*X1_2.dag()\n",
    "rho_init_dict['e+gg'] = X1_2*X0*rho_init*X0.dag()*X1_2.dag()\n",
    "rho_init_dict['+egg'] = X1*X0_2*rho_init*X0_2.dag()*X1.dag()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho_test = project_qubit_subpace(rho_init_dict['eggg'], qram)\n",
    "n_counts = tomo.generate_counts(rho_test, 5000, psi_basis_flat=tomo.psi_basis_flat, noise=0)\n",
    "print(n_counts[0])\n",
    "rho_test = project_qubit_subpace(rho_init_dict['+ggg'], qram)\n",
    "n_counts = tomo.generate_counts(rho_test, 5000, psi_basis_flat=tomo.psi_basis_flat, noise=0)\n",
    "print(n_counts[0])\n",
    "\n",
    "\n",
    "\n",
    "rho_expt = tomo.get_rho_from_counts(n_counts, calib_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tomo.show_plot_rho_2d(rho_expt, rho_test, title='Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho_test = project_qubit_subpace(rho_init_dict['gggg'], qram)\n",
    "qt.ptrace(rho_test, [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qt.ptrace(rho_init_dict['+ggg'],[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SWAPs plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/Volumes/slab/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os\n",
    "\n",
    "for file in glob.glob(data_dir + '/*'):\n",
    "    # show the file name\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_q1q3_right = '00035_length_rabi_EgGf_qubit31.h5'\n",
    "filename_q1q3_wrong = '00037_length_rabi_EgGf_qubit31.h5'\n",
    "filename_q1q2_right = '00038_length_rabi_EgGf_qubit21.h5'\n",
    "filename_q1q2_wrong = '00040_length_rabi_EgGf_qubit21.h5'\n",
    "\n",
    "# filename_q1q3_right = '00133_length_rabi_EgGf_qubit31.h5'\n",
    "# filename_q1q3_wrong = '00134_length_rabi_EgGf_qubit31.h5'\n",
    "# filename_q1q2_right = '00000_length_rabi_EgGf_qubit12.h5'\n",
    "# filename_q1q2_wrong = '00001_length_rabi_EgGf_qubit12.h5'\n",
    "\n",
    "folder = 'data_241025'\n",
    "\n",
    "files = []\n",
    "\n",
    "for f in [filename_q1q3_right, filename_q1q3_wrong, filename_q1q2_right, filename_q1q2_wrong]:\n",
    "    file = h5py.File(data_dir + '/' + folder + '/' + f, 'r')\n",
    "    files.append(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t13 = np.asarray(files[0]['xpts'])\n",
    "t12 = np.asarray(files[2]['xpts'])\n",
    "amp_13_right = np.asarray(files[0]['amps'])\n",
    "amp_13_wrong = np.asarray(files[1]['amps'])\n",
    "amp_12_right = np.asarray(files[2]['amps'])\n",
    "amp_12_wrong = np.asarray(files[3]['amps'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 1, figsize=(5, 3.5))\n",
    "\n",
    "\n",
    "\n",
    "y = amp_13_right[1]\n",
    "y2 = amp_13_wrong[1]\n",
    "\n",
    "y13_1_scaled = (y - np.min(y))/(np.max(y) - np.min(y))\n",
    "y13_2_scaled = (y2 - np.min(y))/(np.max(y) - np.min(y)) \n",
    "\n",
    "# y13_1_scaled = y \n",
    "# y13_2_scaled = y2\n",
    "\n",
    "\n",
    "y = amp_12_right[1]\n",
    "y2 = amp_12_wrong[1]\n",
    "\n",
    "y12_1_scaled = (y - np.min(y))/(np.max(y) - np.min(y))\n",
    "y12_2_scaled = (y2 - np.min(y))/(np.max(y) - np.min(y))\n",
    "\n",
    "# y12_1_scaled = y \n",
    "# y12_2_scaled = y2\n",
    "\n",
    "\n",
    "\n",
    "# fit both with a cosine function\n",
    "\n",
    "# def fit_cos(x, A, B, C, D):\n",
    "#     return A*np.cos(B*x + C) + D\n",
    "\n",
    "# popt, pcov = opt.curve_fit(fit_cos, t13, y1_scaled, p0=[0.5, 2*np.pi/0.5, 0, 0.5])\n",
    "# popt2, pcov2 = opt.curve_fit(fit_cos, t13, y2_scaled, p0=[0.1, 2*np.pi/5, 0, 0.5], maxfev=10000)\n",
    "\n",
    "# y1_fit = fit_cos(t13, *popt)\n",
    "# y2_fit = fit_cos(t13, *popt2)\n",
    "\n",
    "ax[1].plot(t13, y13_1_scaled, 'o-', label=r'$|e\\rangle$', color='#ab4d44')\n",
    "ax[1].plot(t13, y13_2_scaled, 'o-', label=r'$|g\\rangle$', color='#445fab')\n",
    "# set subtitle\n",
    "ax[1].set_title('input - output 2')\n",
    "\n",
    "ax[0].plot(t12, y12_1_scaled, 'o-', label=r'$|g\\rangle$', color='#445fab')\n",
    "ax[0].plot(t12, y12_2_scaled, 'o-', label=r'$|e\\rangle$', color='#ab4d44')\n",
    "# set subtitle\n",
    "ax[0].set_title('input - output 1')\n",
    "\n",
    "ax[0].set_ylabel('Amplitude (a.u.)')\n",
    "ax[1].set_ylabel('Amplitude (a.u.)')\n",
    "\n",
    "ax[1].set_xlabel('Time (ns)')\n",
    "\n",
    "ax[0].legend(title='switch state')\n",
    "ax[0].legend(title='switch state')\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "\n",
    "fig.savefig('rabi_eg_gf.pdf')\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(4, 2))\n",
    "ax.plot(t13, y13_1_scaled, '-o')\n",
    "ax.set_xlabel('Time (ns)')\n",
    "ax.set_ylabel('Amplitude (a.u.)')\n",
    "fig.tight_layout()\n",
    "fig.savefig('rabi_vs_time.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SWAP chevron "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['amps', 'avgi', 'avgq', 'freqpts', 'gainpts', 'phases']>\n"
     ]
    }
   ],
   "source": [
    "# filename_q1q3 = '00000_rabi_EgGf_freqgain_chevron_qubit31.h5'\n",
    "filename_q1q3 = '00000_rabi_EgGf_freqgain_chevron_qubit21.h5'\n",
    "folder = 'data_241025'\n",
    "file = h5py.File(data_dir + '/' + folder + '/' + filename_q1q3, 'r')\n",
    "\n",
    "print(file.keys())\n",
    "\n",
    "\n",
    "avgi = np.asarray(file['amps'])\n",
    "freqs = np.asarray(file['freqpts'])\n",
    "gains = np.asarray(file['gainpts'])\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 100, 25)\n",
      "(100,)\n",
      "(25,)\n"
     ]
    }
   ],
   "source": [
    "print(avgi.shape)\n",
    "print(freqs.shape)\n",
    "print(gains.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do a 2D plot of the data\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(9/1.3, 3.5/1.3))\n",
    "\n",
    "# amp_q0_scaled = (avgi[0] - np.min(avgi[0]))/(np.max(avgi[0]) - np.min(avgi[0]))\n",
    "# amp_q1_scaled = (avgi[1] - np.min(avgi[1]))/(np.max(avgi[1]) - np.min(avgi[1]))\n",
    "\n",
    "\n",
    "amp_q0_scaled = np.abs(avgi[0] - np.median(avgi[0]))\n",
    "amp_q1_scaled = np.abs(avgi[1] - np.median(avgi[1]))\n",
    "\n",
    "# im = ax[0].imshow(amp_q0_scaled, aspect='auto', origin='lower', extent=[gains[0]/gains[-1], gains[-1]/gains[-1], freqs[0]/1e3, freqs[-1]/1e3])\n",
    "im = ax[0].imshow(amp_q0_scaled, aspect='auto', origin='lower', extent=[gains[0], gains[-1], freqs[0]/1e3, freqs[-1]/1e3])\n",
    "# vertical color bar\n",
    "cbar = fig.colorbar(im, ax=ax[0], orientation='vertical', label='Amplitude (a.u.)')\n",
    "ax[0].set_xlabel('Gain (a.u.)')\n",
    "ax[0].set_ylabel('Sideband Frequency (GHz)')\n",
    "ax[0].set_title(r'Output 2')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# im = ax[1].imshow(amp_q1_scaled, aspect='auto', origin='lower', extent=[gains[0]/gains[-1], gains[-1]/gains[-1], freqs[0]/1e3, freqs[-1]/1e3])\n",
    "# im = ax[1].imshow(amp_q1_scaled, aspect='auto', origin='lower', extent=[gains[0]/gains[-1], gains[-1]/gains[-1], freqs[0]/1e3, freqs[-1]/1e3])\n",
    "im = ax[1].imshow(amp_q1_scaled, aspect='auto', origin='lower', extent=[gains[0], gains[-1], freqs[0]/1e3, freqs[-1]/1e3])\n",
    "# vertical color bar\n",
    "cbar = fig.colorbar(im, ax=ax[1], label='Amplitude (a.u.)')\n",
    "ax[1].set_xlabel('Gain (a.u.)')\n",
    "ax[1].set_ylabel('Sideband Frequency (GHz)')\n",
    "ax[1].set_title(r'Input')\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.savefig('rabi_eg_gf_freqgain_chevron_qubit31.pdf')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "amp = amp_q0_scaled + amp_q1_scaled\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(4, 3.5))\n",
    "\n",
    "im = ax.imshow(amp, aspect='auto', origin='lower', extent=[gains[0], gains[-1], freqs[0]/1e3, freqs[-1]/1e3])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1e80595cb50>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plot few slice \n",
    "\n",
    "gain_plot = [5000, 10000, 15000, 20000, 25000]\n",
    "\n",
    "# fig, ax = plt.subplots(1, 2, figsize=(9, 2.5))\n",
    "fig2, ax2 = plt.subplots(1, 1, figsize=(4, 2.5))\n",
    "\n",
    "for idx, g in enumerate(gain_plot):\n",
    "    \n",
    "    idx_g = np.argmin(np.abs(gains - g))\n",
    "    # ax[0].plot(freqs/1e3, amp_q0_scaled[:, idx_g], label='Output 2')\n",
    "    # ax[1].plot(freqs/1e3, amp_q1_scaled[:, idx_g], label='Output 1')\n",
    "    ax2.plot(freqs/1e3, amp[:, idx_g], label='gain = ' + str(g))\n",
    "    \n",
    "ax2.set_xlabel('Sideband Frequency (GHz)')\n",
    "ax2.set_ylabel('Amplitude (a.u.)')\n",
    "ax2.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 25)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import \n",
    "filename_q1q3 = '00000_rabi_EgGf_freqgain_chevron_qubit21.h5'\n",
    "folder = 'data_241025'\n",
    "file = h5py.File(data_dir + '/' + folder + '/' + filename_q1q3, 'r')\n",
    "\n",
    "print(file.keys())\n",
    "\n",
    "avgi = np.asarray(file['amps'])\n",
    "freqs = np.asarray(file['freqpts'])\n",
    "gains = np.asarray(file['gainpts'])\n",
    "\n",
    "\n",
    "# scale the amplitude by the median\n",
    "amp_q0_scaled = np.abs(avgi[0] - np.median(avgi[0]))\n",
    "amp_q1_scaled = np.abs(avgi[1] - np.median(avgi[1]))\n",
    "amp = amp_q0_scaled + amp_q1_scaled\n",
    "\n",
    "\n",
    "# find opt point for each gain\n",
    "freq_opt = np.zeros(len(gains))\n",
    "amp_opt = np.zeros(len(gains))\n",
    "\n",
    "for idx, g in enumerate(gains):\n",
    "    idx_max = np.argmax(amp[:, idx])\n",
    "    freq_opt[idx] = freqs[idx_max]\n",
    "    amp_opt[idx] = amp[idx_max, idx]\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "# fit the optimal gain vs frequency with a 2nd order polynomial\n",
    "\n",
    "def fit_poly(x, a, b, c):\n",
    "    return a*x**2 + b*x + c\n",
    "\n",
    "popt, pcov = opt.curve_fit(fit_poly, gains, freq_opt, p0=[1, 1, 1])\n",
    "popt2, pcov2 = opt.curve_fit(fit_poly, gains, amp_opt, p0=[1, 1, 1])\n",
    "\n",
    "\n",
    "# plot\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(6, 3))\n",
    "\n",
    "\n",
    "ax[0].plot(gains, freq_opt/1e3, 'o-')\n",
    "ax[1].plot(gains, amp_opt, 'o-')\n",
    "\n",
    "ax[0].plot(gains, fit_poly(gains, *popt)/1e3, '--', label='fit')\n",
    "ax[1].plot(gains, fit_poly(gains, *popt2), '--', label='fit')\n",
    "\n",
    "ax[0].set_xlabel('Gain (a.u.)')\n",
    "ax[1].set_xlabel('Gain (a.u.)')\n",
    "ax[0].set_ylabel('Optimal Frequency (GHz)')\n",
    "ax[1].set_ylabel('Optimal Amplitude (a.u.)')\n",
    "\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for all the slice find the maximum and the corresponding frequency\n",
    "\n",
    "freq_opt = np.zeros(len(gains))\n",
    "amp_opt = np.zeros(len(gains))\n",
    "\n",
    "for idx, g in enumerate(gains):\n",
    "    idx_max = np.argmax(amp[:, idx])\n",
    "    freq_opt[idx] = freqs[idx_max]\n",
    "    amp_opt[idx] = amp[idx_max, idx]\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "# fit the optimal gain vs frequency with a 2nd order polynomial\n",
    "\n",
    "def fit_poly(x, a, b, c):\n",
    "    return a*x**2 + b*x + c\n",
    "\n",
    "popt, pcov = opt.curve_fit(fit_poly, gains, freq_opt, p0=[1, 1, 1])\n",
    "popt2, pcov2 = opt.curve_fit(fit_poly, gains, amp_opt, p0=[1, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(6, 3))\n",
    "\n",
    "\n",
    "ax[0].plot(gains, freq_opt/1e3, 'o-')\n",
    "ax[1].plot(gains, amp_opt, 'o-')\n",
    "\n",
    "ax[0].plot(gains, fit_poly(gains, *popt)/1e3, '--', label='fit')\n",
    "ax[1].plot(gains, fit_poly(gains, *popt2), '--', label='fit')\n",
    "\n",
    "ax[0].set_xlabel('Gain (a.u.)')\n",
    "ax[1].set_xlabel('Gain (a.u.)')\n",
    "ax[0].set_ylabel('Optimal Frequency (GHz)')\n",
    "ax[1].set_ylabel('Optimal Amplitude (a.u.)')\n",
    "\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SWAP calibration wrong state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder = 'data_241025'\n",
    "# filename_q1q2 = '00000_eggf_1qtomo_sweepQ2_tomoQ2.h5'\n",
    "# filename_q1q3 = '00002_eggf_1qtomo_sweepQ3_tomoQ3.h5'\n",
    "\n",
    "# file_q1q2 = h5py.File(data_dir + '/' + folder + '/' + filename_q1q2, 'r')\n",
    "# file_q1q3 = h5py.File(data_dir + '/' + folder + '/' + filename_q1q3, 'r')\n",
    "\n",
    "file_q1q2 = np.load('/Volumes/slab/QRAM/qram_4QR2/q1q2.npz')\n",
    "file_q1q3 = np.load('/Volumes/slab/QRAM/qram_4QR2/q1q3.npz')\n",
    "\n",
    "\n",
    "print(file_q1q2.keys())\n",
    "\n",
    "\n",
    "file_q1q2_th = np.load('qutip/pop_q2.npz')\n",
    "file_q1q3_th = np.load('qutip/pop_q3.npz')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_q1q2_th.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freq_q1q2= np.asarray(file_q1q2['freq_sweep'])\n",
    "# freq_q1q3= np.asarray(file_q1q3['freq_sweep'])\n",
    "# gain_q1q2 = np.asarray(file_q1q2['gain_sweep'])\n",
    "# gain_q1q3 = np.asarray(file_q1q3['gain_sweep'])\n",
    "# len_q1q2 = np.asarray(file_q1q2['len_sweep'])\n",
    "# len_q1q3 = np.asarray(file_q1q3['len_sweep'])\n",
    "# ge_avg_q1q2 = np.asarray(file_q1q2['ge_avgs'])\n",
    "# ge_avg_q1q3 = np.asarray(file_q1q3['ge_avgs'])\n",
    "\n",
    "\n",
    "\n",
    "freq_q1q2 = np.unique(file_q1q2['freq_sweep'])\n",
    "gain_q1q2 = np.unique(file_q1q2['gain_sweep'])\n",
    "len_q1q2 = np.unique(file_q1q2['len_sweep'])\n",
    "e_pop_q1q2 = file_q1q2['e_pop_avg']\n",
    "\n",
    "freq_q1q3 = np.unique(file_q1q3['freq_sweep'])\n",
    "gain_q1q3 = np.unique(file_q1q3['gain_sweep'])\n",
    "len_q1q3 = np.unique(file_q1q3['len_sweep'])\n",
    "e_pop_q1q3 = file_q1q3['e_pop_avg']\n",
    "\n",
    "\n",
    "\n",
    "t_vec_12 = file_q1q2_th['t_vec_12']\n",
    "t_vec_13 = file_q1q3_th['t_vec_13']\n",
    "pop_q2 = file_q1q2_th['pop_q2']\n",
    "pop_q3 = file_q1q3_th['pop_q3']\n",
    "amp_vec_12 = file_q1q2_th['amp_vec_12']\n",
    "amp_vec_13 = file_q1q3_th['amp_vec_13']\n",
    "w_vec_12 = file_q1q2_th['w_vec_12']\n",
    "w_vec_13 = file_q1q3_th['w_vec_13']\n",
    "\n",
    "\n",
    "# close the files\n",
    "\n",
    "file_q1q2.close()\n",
    "file_q1q3.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(3,2))\n",
    "ax.plot(len_q1q2*1e3, freq_q1q2/1e3, 'o', color='#445fab', label='data')\n",
    "ax.plot(t_vec_12, w_vec_12/2/np.pi, color='black', label='theory')\n",
    "\n",
    "ax.set_xlabel('$t_\\pi$ (ns)')\n",
    "ax.set_ylabel('$f_\\mathrm{eg-gf}^\\mathrm{in-out1}$ (GHz)')\n",
    "ax.legend()\n",
    "fig.tight_layout()\n",
    "\n",
    "fig2, ax2 = plt.subplots(1, 1, figsize=(3,2))\n",
    "ax2.plot(len_q1q3*1e3, (freq_q1q3)/1e3, 'o', color='#ab4d44', label='data')\n",
    "ax2.plot(t_vec_13, w_vec_13/2/np.pi, color='black', label='theory')\n",
    "\n",
    "ax2.set_xlabel('$t_\\pi$ (ns)')\n",
    "ax2.set_ylabel('$f_\\mathrm{eg-gf}^\\mathrm{in-out2}$ (GHz)')\n",
    "ax2.legend()\n",
    "fig2.tight_layout()\n",
    "\n",
    "fig.savefig('freq_vs_len_q1q2.pdf')\n",
    "fig2.savefig('freq_vs_len_q1q3.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(3, 2))\n",
    "\n",
    "ax.plot(t_vec_12, pop_q2*100, color='black', label='theory')\n",
    "ax.plot(len_q1q2*1e3, e_pop_q1q2[::-1]*100, 'o', color='#ab4d44', label='data')\n",
    "ax.set_xlabel('Time (ns)')\n",
    "ax.set_ylabel('Population (%)')\n",
    "ax.legend()\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.savefig('wrongpop_vs_time_q1q2.pdf')\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(3, 2))\n",
    "ax.plot(t_vec_13, pop_q3*100, color='black', label='theory')\n",
    "ax.plot(len_q1q3*1e3, e_pop_q1q3[::-1]*100, 'o', color='#445fab', label='data')\n",
    "ax.set_xlabel('Time (ns)')\n",
    "ax.set_ylabel('Population (%)')\n",
    "ax.legend()\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.savefig('wrongpop_vs_time_q1q3.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paper plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SWAPs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_chevron = '00213_rabi_EgGf_freqlen_chevron_qubit21.h5'\n",
    "filename_01 = '00216_rabi_EgGf_freqlen_chevron_qubit21.h5'\n",
    "filename_11 = '00217_rabi_EgGf_freqlen_chevron_qubit21.h5'\n",
    "# filename_11 = '00215_rabi_EgGf_freqlen_chevron_qubit21.h5'\n",
    "\n",
    "folder = 'data_240617'\n",
    "\n",
    "file = h5py.File(folder+'/'+filename_chevron, 'r')\n",
    "\n",
    "\n",
    "freqs = np.asarray(file['freqpts'])\n",
    "time = np.asarray(file['lenpts'])\n",
    "amps = np.asarray(file['amps'])\n",
    "\n",
    "file_01 = h5py.File(folder+'/'+filename_01, 'r')\n",
    "freqs_01 = np.asarray(file_01['freqpts'])\n",
    "time_01 = np.asarray(file_01['lenpts'])\n",
    "amps_01 = np.asarray(file_01['amps'])\n",
    "\n",
    "file_11 = h5py.File(folder+'/'+filename_11, 'r')\n",
    "freqs_11 = np.asarray(file_11['freqpts'])\n",
    "time_11 = np.asarray(file_11['lenpts'])\n",
    "amps_11 = np.asarray(file_11['amps'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the idx for which the amps[0] is the maximum\n",
    "\n",
    "\n",
    "amp_plot = amps[0][:,  ::-1].T\n",
    "\n",
    "idx = np.argmax(amp_plot)\n",
    "\n",
    "# unravel the data\n",
    "idx = np.unravel_index(idx, amp_plot.shape)\n",
    "\n",
    "print('idx:', idx)\n",
    "print('freq:', freqs[idx[1]])\n",
    "print('time:', time[::-1][idx[0]])\n",
    "\n",
    "freq_plot = freqs - freqs[idx[1]]\n",
    "time_plot = time[::-1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(3.25, 3/1.2))\n",
    "\n",
    "# 2q maps for the chevron sequence\n",
    "\n",
    "ax.imshow(amp_plot, extent=[freq_plot[0], freq_plot[-1], time_plot[-1], time_plot[0]], aspect='auto')\n",
    "\n",
    "# add color bar\n",
    "cbar = fig.colorbar(im, ax=ax, label='Population (a.u.)')\n",
    "\n",
    "ax.set_xlabel(r'$f - f_\\mathrm{eg-gf}^\\mathrm{in-out1}$ (MHz)')\n",
    "ax.set_ylabel('Time ($\\mu$s)')\n",
    "\n",
    "# add horizontal and vertical lines to show the maximum\n",
    "\n",
    "# ax.axvline(freq_plot[idx[1]], color='black', linestyle='--')\n",
    "# ax.axhline(time_plot[idx[0]], color='black', linestyle='--')\n",
    "\n",
    "\n",
    "xlim = [freq_plot[idx[1]]-6, freq_plot[idx[1]]+1]\n",
    "ylim = [time_plot[-1], time_plot[0]]\n",
    "\n",
    "ax.set_xlim([freq_plot[idx[1]]-6, freq_plot[idx[1]]+1])\n",
    "\n",
    "# set the xticks to show the frequency of the qubit\n",
    "\n",
    "x_ticks = [-6, -4, -2, 0, 2]\n",
    "ax.set_xticks(x_ticks)\n",
    "y_ticks = np.arange(0, ylim[-1], 0.4)\n",
    "ax.set_yticks(y_ticks)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig('chevron_map.pdf', dpi=300)\n",
    "fig.savefig('chevron_map.svg', dpi=300)\n",
    "\n",
    "\n",
    "# # plot the frequency slice\n",
    "\n",
    "# fig, ax2 = plt.subplots(1, 1)\n",
    "\n",
    "\n",
    "# y_e = (amp_plot[idx[0], :] - np.min(amp_plot[idx[0], :]))/ (np.max(amp_plot[idx[0], :] - np.min(amp_plot[idx[0], :])))\n",
    "\n",
    "# ax2.plot(freq_plot, y_e,'-o', color='#ab4d44')\n",
    "# ax2.plot(freq_plot - 5, y_e,'-o', color='#445fab')\n",
    "\n",
    "# ax2.set_xlabel(r'$f - f_{eg-gf}^{12}$ (MHz)')\n",
    "# ax2.set_ylabel('Amplitude (a.u.)')\n",
    "\n",
    "# fig.tight_layout()\n",
    "# fig.savefig('chevron_slice.pdf', dpi=300)\n",
    "# fig.savefig('chevron_slice.svg', dpi=300)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(3.25, 2))\n",
    "\n",
    "x0 = freqs_01 - freqs[idx[1]]\n",
    "y0 = amps_01[0][:, 0].T\n",
    "\n",
    "y0_scaled = (y0 - np.min(y0))/(np.max(y0) - np.min(y0))\n",
    "\n",
    "idx_max_01 = np.argmax(y0)\n",
    "\n",
    "x1 = freqs_11 - freqs[idx[1]]\n",
    "y1 = amps_11[0][:, 0].T\n",
    "\n",
    "y1_scaled = (y1 - np.min(y1))/(np.max(y1) - np.min(y1))\n",
    "\n",
    "idx_max_11 = np.argmax(y1)\n",
    "\n",
    "# ax.plot(x0, y0_scaled, '-o', color='#ab4d44', label=r'$|g\\rangle$')\n",
    "# ax.plot(x1, y1_scaled, '-o', color='#445fab', label=r'$|e\\rangle$')\n",
    "\n",
    "ax.plot(x1, y1_scaled, '-o', color='#ab4d44', label=r'$|e\\rangle$')\n",
    "ax.plot(x0, y0_scaled, '-o', color='#445fab', label=r'$|g\\rangle$')\n",
    "\n",
    "delta_f = x0[idx_max_01] - x1[idx_max_11]\n",
    "print('delta_f:', delta_f)\n",
    "\n",
    "xlim = [x0[idx_max_01]-5.3, x1[idx_max_11]+5.3]\n",
    "\n",
    "ax.set_xlim(xlim)\n",
    "\n",
    "ax.set_ylabel('Amplitude (a.u.)')\n",
    "ax.set_xlabel(r'$f - f_{eg}^{12}$ (MHz)')\n",
    "# put the legend on the back \n",
    "ax.legend(loc='upper right', frameon=False, title='switch state')\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig('chevron_01_11.pdf', dpi=300)\n",
    "fig.savefig('chevron_01_11.svg', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the theoretical model for the chevron sequence\n",
    "file = np.load('pop_q2.npz')\n",
    "\n",
    "t_vec_12= np.asarray(file['t_vec_12'])\n",
    "pop_q2 = np.asarray(file['pop_q2'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(3.25, 2.5))\n",
    "\n",
    "ax.plot(t_vec_12, pop_q2, '-', color='#2b2f36', label='Theory')\n",
    "\n",
    "ax.set_ylabel(r'$P_\\mathrm{e}$ in $\\mathrm{O}_1$')\n",
    "ax.set_xlabel('Pulse length (ns)')\n",
    "fig.tight_layout()\n",
    "\n",
    "# save the figure\n",
    "\n",
    "fig.savefig('chevron_theory.pdf', dpi=300)\n",
    "fig.savefig('chevron_theory.svg', dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[0.9, 0.1], [0.2, 0.8]])\n",
    "A_inv = np.linalg.inv(A)\n",
    "p = np.array([0.3, 0.7]).T\n",
    "p_corr = np.dot(A_inv.T, p)\n",
    "# normalize the corrected probabilities\n",
    "print(p_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
